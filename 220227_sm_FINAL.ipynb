{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teamgaon/KLUE/blob/main/220227_sm_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 라이브러리, 패키지"
      ],
      "metadata": {
        "id": "L4lTVQHqCbcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee9BbI2znxA0",
        "outputId": "a875c5a1-c1ed-4767-e18e-adc19167b22f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31KhLlUBlz_2",
        "outputId": "5c629b47-6a65-48ac-9f7a-4349b8a099de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-1.18.3-py3-none-any.whl (311 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 81 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 311 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting transformers[sentencepiece]\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 69.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 81.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
            "\u001b[K     |████████████████████████████████| 134 kB 79.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 69.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 76.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 79.7 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 67.8 MB/s \n",
            "\u001b[?25hCollecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 77.2 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 73.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n",
            "Collecting sentencepiece!=0.1.92,>=0.1.91\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 71.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (7.1.2)\n",
            "Installing collected packages: multidict, frozenlist, yarl, pyyaml, asynctest, async-timeout, aiosignal, tokenizers, sacremoses, huggingface-hub, fsspec, aiohttp, xxhash, transformers, sentencepiece, datasets\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-1.18.3 frozenlist-1.3.0 fsspec-2022.2.0 huggingface-hub-0.4.0 multidict-6.0.2 pyyaml-6.0 sacremoses-0.0.47 sentencepiece-0.1.96 tokenizers-0.11.5 transformers-4.16.2 xxhash-3.0.0 yarl-1.7.2\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.5.1-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.21.5)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->accelerate) (3.10.0.2)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.5.1\n",
            "Collecting torch-xla==1.9\n",
            "  Downloading https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl (149.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 149.9 MB 23 kB/s \n",
            "\u001b[?25hCollecting cloud-tpu-client==0.10\n",
            "  Downloading cloud_tpu_client-0.10-py3-none-any.whl (7.4 kB)\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |█████████████████████████████▋  | 769.6 MB 1.1 MB/s eta 0:00:55"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers[sentencepiece]\n",
        "!pip install accelerate\n",
        "# To run the training on TPU, you will need to uncomment the followin line:\n",
        "!pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import Accelerator"
      ],
      "metadata": {
        "id": "_vxmupBjnvqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import AutoModel,AutoModelForSequenceClassification, AutoConfig, AutoTokenizer\n",
        "import gc\n",
        "from transformers import AdamW\n",
        "from transformers import get_scheduler, get_cosine_with_hard_restarts_schedule_with_warmup\n",
        "from tqdm.auto import tqdm\n",
        "from datasets import load_metric\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from accelerate import notebook_launcher"
      ],
      "metadata": {
        "id": "R7yZowtOokD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터"
      ],
      "metadata": {
        "id": "EzUFPX_cChcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH =  '/content/drive/MyDrive/KLUE'\n",
        "\n",
        "# 데이콘 데이터셋\n",
        "train = pd.read_csv(os.path.join(PATH, 'train_data.csv'), encoding='utf-8')\n",
        "test = pd.read_csv(os.path.join(PATH, 'test_data.csv'), encoding='utf-8')\n",
        "\n",
        "# 카카오 데이터셋\n",
        "kakao_dev = pd.read_csv('/content/drive/MyDrive/KLUE/xnli.dev.ko.tsv', sep='\\t', encoding='utf-8')\n",
        "kakao_test = pd.read_csv('/content/drive/MyDrive/KLUE/xnli.test.ko.tsv', sep='\\t', encoding='utf-8')\n",
        "kakao_dev = pd.concat([kakao_dev,kakao_test])\n",
        "kakao_dev.rename(columns = {'sentence1':'premise','sentence2':'hypothesis','gold_label':'label'},inplace=True)\n",
        "\n",
        "# KLUE 데이터셋\n",
        "klue_dev = pd.read_json('/content/drive/MyDrive/KLUE/klue-nli-v1.1_dev.json')\n",
        "klue_dev = klue_dev[['premise', 'hypothesis', 'gold_label']]\n",
        "klue_dev.rename(columns = {'gold_label':'label'}, inplace=True)\n",
        "\n",
        "# 데이콘, 카카오, KLUE 데이터셋 병합\n",
        "train = pd.concat([train, klue_dev, kakao_dev], axis=0)\n",
        "train = train.reset_index(drop=True)\n",
        "train['index'] = train.index\n",
        "train = train.dropna()\n",
        "train = train.reset_index(drop=True)\n",
        "train['index'] = train.index\n",
        "train"
      ],
      "metadata": {
        "id": "PpIow7U5n0ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 토크나이저, 함수"
      ],
      "metadata": {
        "id": "fx9yGQxtClQ4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGWbl8edlz_5"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = 'klue/roberta-large'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, pair_dataset, label):\n",
        "        self.pair_dataset = pair_dataset\n",
        "        self.label = label\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx].clone().detach() for key, val in self.pair_dataset.items()}\n",
        "        item['labels'] = torch.tensor(self.label[idx])\n",
        "        \n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)"
      ],
      "metadata": {
        "id": "J3OrqrY3or6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_to_num(label):\n",
        "    label_dict = {\"entailment\": 0, \"contradiction\": 1, \"neutral\": 2, \"answer\": 3}\n",
        "    num_label = []\n",
        "\n",
        "    for v in label:\n",
        "        num_label.append(label_dict[v])\n",
        "    \n",
        "    return num_label"
      ],
      "metadata": {
        "id": "bqgw3AKZotnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc"
      ],
      "metadata": {
        "id": "bs0VFrWuA_6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습"
      ],
      "metadata": {
        "id": "uep3CPkqCWWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_function():\n",
        "  accelerator = Accelerator()\n",
        "\n",
        "  train_dataloader = torch.utils.data.DataLoader(\n",
        "                    train_dataset, \n",
        "                    batch_size=16, sampler=train_subsampler)\n",
        "  eval_dataloader = torch.utils.data.DataLoader(\n",
        "                    train_dataset,\n",
        "                    batch_size=16, sampler=test_subsampler)\n",
        "\n",
        "  config = AutoConfig.from_pretrained(checkpoint)\n",
        "  config.num_labels = 3\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(checkpoint, config=config)\n",
        "\n",
        "  optimizer = AdamW(model.parameters(), lr=\t1e-5)\n",
        "\n",
        "  model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(model, optimizer, train_dataloader, eval_dataloader)\n",
        "\n",
        "  num_epochs = 5\n",
        "  num_training_steps = num_epochs * len(train_dataloader)\n",
        "  progress_bar = tqdm(range(num_training_steps))\n",
        "  lr_scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(\n",
        "      optimizer=optimizer,\n",
        "      num_warmup_steps=1,\n",
        "      num_training_steps=num_training_steps,\n",
        "  )\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      train_acc = 0.0\n",
        "      test_acc = 0.0\n",
        "\n",
        "      model.train()\n",
        "      for batch_id, batch in enumerate(train_dataloader):\n",
        "          outputs = model(batch['input_ids'], batch['attention_mask'], batch['token_type_ids'])\n",
        "          loss = F.cross_entropy(outputs[0], batch['labels'])\n",
        "          accelerator.backward(loss)\n",
        "\n",
        "          optimizer.step()\n",
        "          lr_scheduler.step()\n",
        "          optimizer.zero_grad()\n",
        "          progress_bar.update(1)\n",
        "          train_acc += calc_accuracy(outputs.logits, batch['labels'])\n",
        "      print(\"epoch {} train acc {}\".format(epoch+1, train_acc / (batch_id+1)))\n",
        "\n",
        "      model.eval()\n",
        "      for batch_id, batch in enumerate(eval_dataloader):\n",
        "        with torch.no_grad():\n",
        "            outputs = model(batch['input_ids'], batch['attention_mask'], batch['token_type_ids'])\n",
        "\n",
        "        test_acc += calc_accuracy(outputs.logits, batch['labels'])\n",
        "      print(\"epoch {} test acc {}\".format(epoch+1, test_acc / (batch_id+1)))\n",
        "      gc.collect()\n",
        "  accelerator.wait_for_everyone()\n",
        "  unwrapped_model = accelerator.unwrap_model(model)\n",
        "  unwrapped_model.save_pretrained('/content/drive/MyDrive/220226/model' + str(fold), save_function=accelerator.save)"
      ],
      "metadata": {
        "id": "miLIkS4ZQnxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "print('--------------------------------')\n",
        "\n",
        "tokenized_train = tokenizer(\n",
        "  list(train['premise']),\n",
        "  list(train['hypothesis']),\n",
        "  return_tensors=\"pt\",\n",
        "  max_length=128, # Max_Length = 190\n",
        "  padding=True,\n",
        "  truncation=True,\n",
        "  add_special_tokens=True\n",
        "  )\n",
        "  \n",
        "for fold, (train_ids, test_ids) in enumerate(kfold.split(train, train['label'])):\n",
        "  print(f'FOLD {fold}')\n",
        "\n",
        "  train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "  test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
        "\n",
        "  train_label = label_to_num(train['label'].values)\n",
        "\n",
        "  train_dataset = BERTDataset(tokenized_train, train_label)\n",
        "\n",
        "  notebook_launcher(training_function)"
      ],
      "metadata": {
        "id": "vJ937XNoPln-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 추론"
      ],
      "metadata": {
        "id": "rbI7DuDDBEhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "test_label = label_to_num(test['label'].values)\n",
        "\n",
        "tokenized_test = tokenizer(\n",
        "    list(test['premise']),\n",
        "    list(test['hypothesis']),\n",
        "    return_tensors=\"pt\",\n",
        "    max_length=128,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    add_special_tokens=True\n",
        ")\n",
        "\n",
        "test_dataset = BERTDataset(tokenized_test, test_label)\n",
        "\n",
        "dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "for fold in range(5):\n",
        "\n",
        "  config = AutoConfig.from_pretrained(checkpoint)\n",
        "  config.num_labels = 3\n",
        "  model = AutoModelForSequenceClassification.from_pretrained('/content/drive/MyDrive/220226/model' + str(fold), num_labels=3)\n",
        "  model.resize_token_embeddings(tokenizer.vocab_size)\n",
        "  accelerator = Accelerator()\n",
        "  model = accelerator.unwrap_model(model)\n",
        "\n",
        "  output_pred = []\n",
        "  output_prob = []\n",
        "\n",
        "  model, dataloader= accelerator.prepare(model, dataloader)\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  for i, data in enumerate(tqdm(dataloader)):\n",
        "      with torch.no_grad():\n",
        "          outputs = model(\n",
        "              input_ids=data['input_ids'],\n",
        "              attention_mask=data['attention_mask']\n",
        "          )\n",
        "      logits = outputs[0]\n",
        "      prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      result = np.argmax(logits, axis=-1)\n",
        "      output_pred.append(result)\n",
        "      output_prob.append(prob)\n",
        "      \n",
        "  pred_answer, output_prob = np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()\n",
        "\n",
        "  def num_to_label(label):\n",
        "      label_dict = {0: \"entailment\", 1: \"contradiction\", 2: \"neutral\"}\n",
        "      str_label = []\n",
        "\n",
        "      for i, v in enumerate(label):\n",
        "          str_label.append([i,label_dict[v]])\n",
        "      \n",
        "      return str_label\n",
        "\n",
        "  answer = num_to_label(pred_answer)\n",
        "\n",
        "  df_label = pd.DataFrame(answer, columns=['index', 'label'])\n",
        "  df_prob = pd.DataFrame(output_prob)\n",
        "\n",
        "  df_label.to_csv('/content/drive/MyDrive/220226/pred_label'+str(fold)+'.csv', index=False)\n",
        "  df_prob.to_csv('/content/drive/MyDrive/220226/pred_prob'+str(fold)+'.csv', index=False)"
      ],
      "metadata": {
        "id": "kQesDl_0qsuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## softvoting"
      ],
      "metadata": {
        "id": "0EbP909ZBGsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred0 = pd.read_csv('/content/drive/MyDrive/220226/pred_prob0.csv')\n",
        "pred1 = pd.read_csv('/content/drive/MyDrive/220226/pred_prob1.csv')\n",
        "pred2 = pd.read_csv('/content/drive/MyDrive/220226/pred_prob2.csv')\n",
        "pred3 = pd.read_csv('/content/drive/MyDrive/220226/pred_prob3.csv')\n",
        "pred4 = pd.read_csv('/content/drive/MyDrive/220226/pred_prob4.csv')"
      ],
      "metadata": {
        "id": "7D976Pqds77c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = pd.DataFrame((np.array(pred0) + np.array(pred1) + np.array(pred2) + np.array(pred3) + np.array(pred4))/5)"
      ],
      "metadata": {
        "id": "m4MyzZvxmlJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(os.path.join(PATH, 'test_data.csv'), encoding='utf-8')"
      ],
      "metadata": {
        "id": "LuNJOhmIhGvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.concat([test, pred], axis=1)"
      ],
      "metadata": {
        "id": "22TNMu7vnSdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0: \"entailment\", 1: \"contradiction\", 2: \"neutral\"\n",
        "test.loc[(test[2] > 0.1) , 'label'] = 'neutral'\n",
        "test.loc[(test[0] > 0.1) , 'label'] = 'entailment'\n",
        "test.loc[(test[1] > 0.1) , 'label'] = 'contradiction'"
      ],
      "metadata": {
        "id": "K9XF5_wOuboT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_label = []\n",
        "for index in test[(test[0] > 0.1) & (test[1] > 0.1) & (test[2] > 0.1)].index:\n",
        "  if test[0].loc[index] > test[1].loc[index] :\n",
        "    my_label.append('entailment')\n",
        "  else:\n",
        "    my_label.append('contradiction')\n",
        "\n",
        "test.loc[(test[(test[0] > 0.1) & (test[1] > 0.1) & (test[2] > 0.1)].index), 'label'] = my_label"
      ],
      "metadata": {
        "id": "7SuW08AIwMrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_label = []\n",
        "for index in test[(test[0] > 0.1) & (test[1] > 0.1)].index:\n",
        "  if test[0].loc[index] > test[1].loc[index] :\n",
        "    my_label.append('entailment')\n",
        "  else:\n",
        "    my_label.append('contradiction')\n",
        "\n",
        "test.loc[(test[(test[0] > 0.1) & (test[1] > 0.1)].index), 'label'] = my_label"
      ],
      "metadata": {
        "id": "4uUy31rr1rtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.loc[(test[(test['label'] == 'entailment') & (test[2] > 0.7)].index), 'label'] = 'neutral'"
      ],
      "metadata": {
        "id": "q86NbL9x2Il5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['label'].value_counts()"
      ],
      "metadata": {
        "id": "Wr8CvGop1QTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/KLUE/sample_submission.csv')"
      ],
      "metadata": {
        "id": "-Q4xegVmA_c4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission['label'] = test['label']"
      ],
      "metadata": {
        "id": "uHq_TCkeA_c4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission"
      ],
      "metadata": {
        "id": "yE0e97BZA_c5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv('/content/drive/MyDrive/220226/submission_soft.csv', index=False)"
      ],
      "metadata": {
        "id": "32thXr4xA_c5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hardvoting"
      ],
      "metadata": {
        "id": "FIW3sqx2A5yE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred0 = pd.read_csv('/content/drive/MyDrive/220226/pred_label0.csv')\n",
        "pred1 = pd.read_csv('/content/drive/MyDrive/220226/pred_label1.csv')\n",
        "pred2 = pd.read_csv('/content/drive/MyDrive/220226/pred_label2.csv')\n",
        "pred3 = pd.read_csv('/content/drive/MyDrive/220226/pred_label3.csv')\n",
        "pred4 = pd.read_csv('/content/drive/MyDrive/220226/pred_label4.csv')"
      ],
      "metadata": {
        "id": "npXR96pIBZl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['label0'] = pred0['label']\n",
        "test['label1'] = pred1['label']\n",
        "test['label2'] = pred2['label']\n",
        "test['label3'] = pred3['label']\n",
        "test['label4'] = pred4['label']"
      ],
      "metadata": {
        "id": "ijSuvL_B6Hdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = test\n",
        "df"
      ],
      "metadata": {
        "id": "3gYfQp2k6I8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_count(df):\n",
        "  num_neutral = 0\n",
        "  num_contradiction = 0\n",
        "  num_entailment = 0\n",
        "  cols = ['label0', 'label1', 'label2', 'label3', 'label4']\n",
        "\n",
        "  for col in cols:\n",
        "    if df[col] == 'neutral':\n",
        "      num_neutral = num_neutral + 1\n",
        "    if df[col] == 'contradiction':\n",
        "      num_contradiction = num_contradiction + 1\n",
        "    if df[col] == 'entailment':\n",
        "      num_entailment = num_entailment + 1\n",
        "\n",
        "  return [num_neutral, num_contradiction, num_entailment]\n",
        "\n",
        "temp = df.apply(label_count, axis=1)\n",
        "df['temp'] = temp\n",
        "\n",
        "df['neutral'] = 0\n",
        "df['contradiction'] = 0\n",
        "df['entailment'] = 0\n",
        "\n",
        "def list_to_num(list:list):\n",
        "  return list[0]\n",
        "df['neutral'] = df['temp'].map(list_to_num)\n",
        "\n",
        "def list_to_num(list:list):\n",
        "  return list[1]\n",
        "df['contradiction'] = df['temp'].map(list_to_num)\n",
        "\n",
        "def list_to_num(list:list):\n",
        "  return list[2]\n",
        "df['entailment'] = df['temp'].map(list_to_num)\n",
        "\n",
        "def voting(df):\n",
        "  cols = ['neutral', 'contradiction', 'entailment']\n",
        "  for col in cols:\n",
        "    if df[col] > 2:\n",
        "      return col\n",
        "  return 'neutral'\n",
        "\n",
        "df['label'] = df.apply(voting, axis=1)"
      ],
      "metadata": {
        "id": "O_Ety9cp6eJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_label(list:list):\n",
        "  if list == [3, 2, 0] :\n",
        "    return 'contradiction'\n",
        "  if list == [3, 0, 2]:\n",
        "    return 'entailment'\n",
        "  if list == [4, 1, 0]:\n",
        "    return 'contradiction'\n",
        "  if list == [4, 0, 1]:\n",
        "    return 'entailment'\n",
        "  else :\n",
        "    return 'answer'\n",
        "\n",
        "my_label = df['temp'].map(make_label)"
      ],
      "metadata": {
        "id": "lJuHtvCp7Za4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['my_label'] = my_label"
      ],
      "metadata": {
        "id": "1Gaz1O3979AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_answer = df[df['my_label'] != 'answer']"
      ],
      "metadata": {
        "id": "eaESvn4J7_aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[my_answer.index, 'label'] = my_answer['my_label']"
      ],
      "metadata": {
        "id": "1aF-xH9N8ryH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "id": "QVmJIcCd8213"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/KLUE/sample_submission.csv')"
      ],
      "metadata": {
        "id": "YjNGWLbe-IP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission['label'] = df['label']"
      ],
      "metadata": {
        "id": "Jt4e9q-Xx6w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission"
      ],
      "metadata": {
        "id": "WyxA4kaQ9MfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv('/content/drive/MyDrive/220226/submission_hard.csv', index=False)"
      ],
      "metadata": {
        "id": "uuMlbsrp9I7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## soft + hard voting"
      ],
      "metadata": {
        "id": "V5xpoBUGpaxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soft = pd.read_csv('/content/drive/MyDrive/220226/submission_soft.csv')\n",
        "hard = pd.read_csv('/content/drive/MyDrive/220226/submission_hard.csv')"
      ],
      "metadata": {
        "id": "l7AWjt9yhAkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = test[['premise',\t'hypothesis',\t'label',\t0,\t1,\t2,\t'label0',\t'label1',\t'label2',\t'label3',\t'label4']]"
      ],
      "metadata": {
        "id": "hVDJtSWBhHpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['soft'] = soft['label']\n",
        "df['hard'] = hard['label']"
      ],
      "metadata": {
        "id": "7GWGK4yQhcup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['soft'].value_counts()"
      ],
      "metadata": {
        "id": "uSDgROSJiP1i",
        "outputId": "4ba6710d-7eca-43ee-df9f-2395000ea26e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral          573\n",
              "entailment       561\n",
              "contradiction    532\n",
              "Name: soft, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['hard'].value_counts()"
      ],
      "metadata": {
        "id": "O26JCuXziS3B",
        "outputId": "6ca8014b-327b-4035-8019-2cecc2a55d81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "entailment       568\n",
              "neutral          555\n",
              "contradiction    543\n",
              "Name: hard, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df[(df['hard'] != df['soft']) & (df['soft'] == 'neutral')].index, 'label'] = df[(df['hard'] != df['soft']) & (df['soft'] == 'neutral')]['soft']"
      ],
      "metadata": {
        "id": "4qDOYC9OiXJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df[(df['hard'] != df['soft']) & (df['soft'] != 'neutral')].index, 'label'] = df[(df['hard'] != df['soft']) & (df['soft'] != 'neutral')]['hard']"
      ],
      "metadata": {
        "id": "F6gHWgakn-Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "id": "i2B1JN56oB38",
        "outputId": "fe2aff3b-2789-4345-83a6-9484d830d096",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral          576\n",
              "entailment       563\n",
              "contradiction    527\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/KLUE/sample_submission.csv')"
      ],
      "metadata": {
        "id": "35Qco9BRp4bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission['label'] = df['label']"
      ],
      "metadata": {
        "id": "OaC4G5xOp4bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "5bd5d8ae-1477-4697-dbce-b07e997b457f",
        "id": "VkyRJzfUp4bL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-85734f7b-0386-45cc-a39d-bf1b8a634356\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1661</th>\n",
              "      <td>1661</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1662</th>\n",
              "      <td>1662</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1663</th>\n",
              "      <td>1663</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1664</th>\n",
              "      <td>1664</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1665</th>\n",
              "      <td>1665</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1666 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85734f7b-0386-45cc-a39d-bf1b8a634356')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85734f7b-0386-45cc-a39d-bf1b8a634356 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85734f7b-0386-45cc-a39d-bf1b8a634356');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      index          label\n",
              "0         0  contradiction\n",
              "1         1        neutral\n",
              "2         2     entailment\n",
              "3         3  contradiction\n",
              "4         4  contradiction\n",
              "...     ...            ...\n",
              "1661   1661        neutral\n",
              "1662   1662     entailment\n",
              "1663   1663        neutral\n",
              "1664   1664        neutral\n",
              "1665   1665        neutral\n",
              "\n",
              "[1666 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv('/content/drive/MyDrive/220226/submission_soft_hard.csv', index=False)"
      ],
      "metadata": {
        "id": "9oYMDGPNp4bL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "A full training",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "TPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}