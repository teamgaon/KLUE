{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teamgaon/KLUE/blob/main/220221_sm_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W2Q9Qbnlz_t"
      },
      "source": [
        "# A full training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCra33qIlz_1"
      },
      "source": [
        "Install the Transformers and Datasets libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee9BbI2znxA0",
        "outputId": "d6937c16-b934-4812-bc0a-24bdaf424f7a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "# k80 -> T4 -> P100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_rufI-bLbuv",
        "outputId": "9ce65b1e-ccc9-4010-947f-390b586bf058"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb 20 09:19:06 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P0    37W / 250W |  13527MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31KhLlUBlz_2",
        "outputId": "18d44b90-7f3b-450f-dbc3-412da1633309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.18.3)\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.11)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.0.47)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.11.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (3.17.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.1.96)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (1.1.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.21.5)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->accelerate) (3.10.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers[sentencepiece]\n",
        "!pip install accelerate\n",
        "# To run the training on TPU, you will need to uncomment the followin line:\n",
        "# !pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# from accelerate import Accelerator"
      ],
      "metadata": {
        "id": "_vxmupBjnvqo"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import AutoModelForSequenceClassification, AutoConfig, AutoTokenizer\n",
        "import gc"
      ],
      "metadata": {
        "id": "R7yZowtOokD_"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accelerator = Accelerator()\n",
        "# device = accelerator.device"
      ],
      "metadata": {
        "id": "-vDRUkYToA1t"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH =  '/content/drive/MyDrive/KLUE'\n",
        "test = pd.read_csv(os.path.join(PATH, 'test_data.csv'), encoding='utf-8')\n",
        "\n",
        "dev_ko = pd.read_csv('/content/drive/MyDrive/KLUE/xnli.dev.ko.tsv', sep='\\t', encoding='utf-8')\n",
        "test_ko = pd.read_csv('/content/drive/MyDrive/KLUE/xnli.test.ko.tsv', sep='\\t', encoding='utf-8')\n",
        "\n",
        "temp = pd.read_csv(os.path.join(PATH, 'train_data.csv'), encoding='utf-8')\n",
        "\n",
        "train = pd.concat([dev_ko,test_ko])\n",
        "train.rename(columns = {'sentence1':'premise','sentence2':'hypothesis','gold_label':'label'},inplace=True)\n",
        "train = pd.concat([temp, train], axis=0)\n",
        "train = train.dropna()\n",
        "train = train.reset_index(drop=True)\n",
        "train['index'] = train.index\n",
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PpIow7U5n0ov",
        "outputId": "0af36793-8c0d-42c8-9812-be5f3f6f46f9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6d471580-4277-44ad-9194-4e134a7fb596\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서, 소년이나 장정들이...</td>\n",
              "      <td>씨름의 여자들의 놀이이다.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나,...</td>\n",
              "      <td>자작극을 벌인 이는 3명이다.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다.</td>\n",
              "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
              "      <td>원주민들은 종합대책에 만족했다.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면, 이런 상황에서는...</td>\n",
              "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24993</th>\n",
              "      <td>24993</td>\n",
              "      <td>오페라에 비하여 오라토리오에서는 독창보다도 합창이 중시되며, 테스토 또는 이스토리쿠...</td>\n",
              "      <td>오라토리오에서 테스토의 역할이 가장 중요하다.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24994</th>\n",
              "      <td>24994</td>\n",
              "      <td>지하철역까지 걸어서 5분 정도 걸립니다.</td>\n",
              "      <td>지하철역까지 도보로 5분 정도 걸립니다.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>24995</td>\n",
              "      <td>한편 이날 중앙방역대책본부는 집단 감염이 발생한 음식점 관련 역학조사 결과를 공개했다.</td>\n",
              "      <td>중악방역대책본부는 집단 감염과 관련한 모든 정보를 비공개했다.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>24996</td>\n",
              "      <td>마미손이 랩을 하자 시청자들은 그의 정체를 파악했다.</td>\n",
              "      <td>시청자들은 마미손의 정체를 안다.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>24997</td>\n",
              "      <td>집근처에 지하철역,버스정류장이 있기때문에 다른 곳으로 이동하는데 좋았습니다.</td>\n",
              "      <td>집 근처에 있는 지하철역을 이용하기 위해서는 걸어서 5분 정도 가야합니다.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24998 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d471580-4277-44ad-9194-4e134a7fb596')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d471580-4277-44ad-9194-4e134a7fb596 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d471580-4277-44ad-9194-4e134a7fb596');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       index  ...          label\n",
              "0          0  ...  contradiction\n",
              "1          1  ...  contradiction\n",
              "2          2  ...     entailment\n",
              "3          3  ...        neutral\n",
              "4          4  ...        neutral\n",
              "...      ...  ...            ...\n",
              "24993  24993  ...        neutral\n",
              "24994  24994  ...     entailment\n",
              "24995  24995  ...  contradiction\n",
              "24996  24996  ...     entailment\n",
              "24997  24997  ...        neutral\n",
              "\n",
              "[24998 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "CGWbl8edlz_5"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = 'klue/roberta-large'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, eval_dataset = train_test_split(train, test_size=0.2, shuffle=False)\n",
        "\n",
        "tokenized_train = tokenizer(\n",
        "    list(train['premise']),\n",
        "    list(train['hypothesis']),\n",
        "    return_tensors=\"pt\",\n",
        "    max_length=128, # Max_Length = 190\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    add_special_tokens=True\n",
        ")\n",
        "\n",
        "tokenized_eval = tokenizer(\n",
        "    list(eval_dataset['premise']),\n",
        "    list(eval_dataset['hypothesis']),\n",
        "    return_tensors=\"pt\",\n",
        "    max_length=128,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    add_special_tokens=True\n",
        ")"
      ],
      "metadata": {
        "id": "L32MUBMXocy6"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, pair_dataset, label):\n",
        "        self.pair_dataset = pair_dataset\n",
        "        self.label = label\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx].clone().detach() for key, val in self.pair_dataset.items()}\n",
        "        item['labels'] = torch.tensor(self.label[idx])\n",
        "        \n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)"
      ],
      "metadata": {
        "id": "J3OrqrY3or6F"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_to_num(label):\n",
        "    label_dict = {\"entailment\": 0, \"contradiction\": 1, \"neutral\": 2, \"answer\": 3}\n",
        "    num_label = []\n",
        "\n",
        "    for v in label:\n",
        "        num_label.append(label_dict[v])\n",
        "    \n",
        "    return num_label\n",
        "\n",
        "\n",
        "train_label = label_to_num(train['label'].values)\n",
        "eval_label = label_to_num(eval_dataset['label'].values)"
      ],
      "metadata": {
        "id": "bqgw3AKZotnU"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = BERTDataset(tokenized_train, train_label)\n",
        "eval_dataset = BERTDataset(tokenized_eval, eval_label)"
      ],
      "metadata": {
        "id": "O9oWnK57owKN"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "id": "V-LGu7eI9cDV",
        "outputId": "9d7e83a1-63a8-4a50-92c9-4ee28d108bdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0]),\n",
              " 'input_ids': tensor([    0, 14441,  2073, 12382, 13169,  2200,  3797, 21505,  9005,  2259,\n",
              "          3997,  2031,  2079,  3661, 31221,  5845,  2200,  2112,    16,  5950,\n",
              "         15351, 17788,  7285,   748,  2088, 22048,  2470,  1132, 21893, 15351,\n",
              "          6481, 27135,  5417,  4084,  1972,  2145, 17524,  2138, 15526,  2259,\n",
              "           575, 28674,    18,     2, 14441,  2079,  3883,  2031,  2079,  5845,\n",
              "         28674,    18,     2,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]),\n",
              " 'labels': tensor(1),\n",
              " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0])}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "tQjBfjjFlz_6"
      },
      "outputs": [],
      "source": [
        "# tokenized_datasets = tokenized_datasets.remove_columns([\"sentence1\", \"sentence2\", \"idx\"])\n",
        "# tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "# tokenized_datasets.set_format(\"torch\")\n",
        "# tokenized_datasets[\"train\"].column_names"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset = train_dataset.rename_column(\"label\", \"labels\")"
      ],
      "metadata": {
        "id": "3BIOYaRUpwKf"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "no-X6O4plz_7"
      },
      "outputs": [],
      "source": [
        "# [\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "PFeqorBIlz_7"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# train_dataloader = DataLoader(\n",
        "#     train_dataset, shuffle=True, batch_size=16\n",
        "# )\n",
        "# eval_dataloader = DataLoader(\n",
        "#     eval_dataset, batch_size=16\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "MRK1oL7ylz_8"
      },
      "outputs": [],
      "source": [
        "# for batch in train_dataloader:\n",
        "#     break\n",
        "# {k: v.shape for k, v in batch.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "vXkV49Fqlz_9"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoModelForSequenceClassification\n",
        "\n",
        "# config = AutoConfig.from_pretrained(checkpoint)\n",
        "# config.num_labels = 3\n",
        "\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(checkpoint, config=config)\n",
        "# model = AutoModel.from_pretrained(\"klue/roberta-large\", num_labels=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "oETwarOwlz_-"
      },
      "outputs": [],
      "source": [
        "# outputs = model(**batch)\n",
        "# print(outputs.loss, outputs.logits.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "sZhzZ-aWlz_-"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "# optimizer = AdamW(model.parameters(), lr=\t0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "FQBdP3Jelz__"
      },
      "outputs": [],
      "source": [
        "from transformers import get_scheduler, get_cosine_with_hard_restarts_schedule_with_warmup\n",
        "\n",
        "# num_epochs = 3\n",
        "# num_training_steps = num_epochs * len(train_dataloader)\n",
        "# lr_scheduler = get_scheduler(\n",
        "#     \"linear\",\n",
        "#     optimizer=optimizer,\n",
        "#     num_warmup_steps=0,\n",
        "#     num_training_steps=num_training_steps,\n",
        "# )\n",
        "# print(num_training_steps)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "# model.to(device)\n",
        "# device"
      ],
      "metadata": {
        "id": "yTYify1RPF1S"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(model, optimizer, train_dataloader, eval_dataloader)"
      ],
      "metadata": {
        "id": "UC_orredqieH"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Ks7aWh4Elz__"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "\n",
        "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "# model.to(device)\n",
        "# device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc"
      ],
      "metadata": {
        "id": "bs0VFrWuA_6u"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_interval = 100"
      ],
      "metadata": {
        "id": "TV1o-u4nDC9a"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "Djc4iH0nl0AA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565,
          "referenced_widgets": [
            "91de12c8cb3e4875b22a75feefd5a2e7",
            "1bb3e2a2bfce4926bdc84ff16353c7b9",
            "b7f023d007ca4b37b2bc416534745179",
            "df5954de8b61444abc29e550ec9284b9",
            "6dc628f645af470fa7469c2075120319",
            "b98b4b18ad6742ac998540a8890f8d63",
            "f02a89beb44a4ff1bb2c48040804bf46",
            "6c112873eaa04cc19a5c5a9a48abc4c0",
            "dc51853a2f4f4b31a86e7a7534663725",
            "ac48f81c7d6f414986e27369d82d9e24",
            "00df1b6abce74e2fa4028f7604aa51e0"
          ]
        },
        "outputId": "1f97fae4-0232-4571-9db3-e10e214e6b36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91de12c8cb3e4875b22a75feefd5a2e7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7820 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 train acc 0.8266464194373402\n",
            "epoch 1 test acc 0.9341162420382165\n",
            "epoch 2 train acc 0.9365808823529411\n",
            "epoch 2 test acc 0.9814888535031847\n",
            "epoch 3 train acc 0.9709079283887468\n",
            "epoch 3 test acc 0.9912420382165605\n",
            "epoch 4 train acc 0.9840153452685422\n",
            "epoch 4 test acc 0.9966162420382165\n",
            "epoch 5 train acc 0.9899696291560103\n",
            "epoch 5 test acc 0.9978105095541401\n",
            "epoch 6 train acc 0.99528452685422\n",
            "epoch 6 test acc 0.9988057324840764\n",
            "epoch 7 train acc 0.9967631074168798\n",
            "epoch 7 test acc 0.9998009554140127\n",
            "epoch 8 train acc 0.9983615728900256\n",
            "epoch 8 test acc 0.9998009554140127\n",
            "epoch 9 train acc 0.9989210358056266\n",
            "epoch 9 test acc 1.0\n",
            "epoch 10 train acc 0.9992407289002557\n",
            "epoch 10 test acc 1.0\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "from datasets import load_metric\n",
        "# progress_bar = tqdm(range(num_training_steps))\n",
        "# metric = load_metric(\"accuracy\")\n",
        "\n",
        "\n",
        "# accelerator = Accelerator()\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "  train_dataset, shuffle=True, batch_size=32\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    eval_dataset, batch_size=32\n",
        ")\n",
        "\n",
        "config = AutoConfig.from_pretrained(checkpoint)\n",
        "config.num_labels = 3\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, config=config)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=\t1e-5)\n",
        "\n",
        "# model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(model, optimizer, train_dataloader, eval_dataloader)\n",
        "\n",
        "num_epochs = 10\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "lr_scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=1,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "\n",
        "    model.train()\n",
        "    for batch_id, batch in enumerate(train_dataloader):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(batch['input_ids'], batch['attention_mask'], batch['token_type_ids'])\n",
        "        loss = F.cross_entropy(outputs[0], batch['labels'])\n",
        "        # print(batch)\n",
        "        loss.backward()\n",
        "        # accelerator.backward(loss)\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "        # print(outputs)\n",
        "        # print('-----------')\n",
        "        # print(batch['labels'])\n",
        "        train_acc += calc_accuracy(outputs.logits, batch['labels'])\n",
        "        # if batch_id  == 100:\n",
        "        #     print(\"epoch {} batch id {} loss {} train acc {}\".format(epoch+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(epoch+1, train_acc / (batch_id+1)))\n",
        "\n",
        "    model.eval()\n",
        "    for batch_id, batch in enumerate(eval_dataloader):\n",
        "      batch = {k: v.to(device) for k, v in batch.items()}\n",
        "      with torch.no_grad():\n",
        "          outputs = model(batch['input_ids'], batch['attention_mask'], batch['token_type_ids'])\n",
        "\n",
        "      # logits = outputs.logits\n",
        "      # predictions = torch.argmax(logits, dim=-1)\n",
        "      test_acc += calc_accuracy(outputs.logits, batch['labels'])\n",
        "    print(\"epoch {} test acc {}\".format(epoch+1, test_acc / (batch_id+1)))\n",
        "      # metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "    # print('epoch : ' + str(epoch))\n",
        "    # accuracy = metric.compute()\n",
        "    # print(accuracy)\n",
        "\n",
        "    gc.collect()\n",
        "    model.save_pretrained('./result/best_model' + str(epoch))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWU5C6oj2veh",
        "outputId": "97e08eee-e11b-4b6b-d2b7-67e3fc309cc4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from accelerate import notebook_launcher\n",
        "# import warnings\n",
        "\n",
        "# warnings.filterwarnings('ignore')\n",
        "# notebook_launcher(training_function)"
      ],
      "metadata": {
        "id": "10duXIf_QYhR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "Tokenizer_NAME = \"klue/roberta-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(Tokenizer_NAME)\n",
        "\n",
        "MODEL_NAME = './result/best_model9'\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\n",
        "model.resize_token_embeddings(tokenizer.vocab_size)\n",
        "model.to(device)\n",
        "\n",
        "print(tokenizer)"
      ],
      "metadata": {
        "id": "efirdTEK_c9z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60ed3c10-8bfe-43ca-b411-8fa84ad95408"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PreTrainedTokenizerFast(name_or_path='klue/roberta-large', vocab_size=32000, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_label = label_to_num(test['label'].values)\n",
        "\n",
        "tokenized_test = tokenizer(\n",
        "    list(test['premise']),\n",
        "    list(test['hypothesis']),\n",
        "    return_tensors=\"pt\",\n",
        "    max_length=128,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    add_special_tokens=True\n",
        ")\n",
        "\n",
        "test_dataset = BERTDataset(tokenized_test, test_label)\n",
        "\n",
        "print(test_dataset.__len__())\n",
        "print(test_dataset.__getitem__(1665))\n",
        "print(tokenizer.decode(test_dataset.__getitem__(6)['input_ids']))"
      ],
      "metadata": {
        "id": "XI5RYcMl_eYw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1b33c69-35a1-4ef6-b2ea-cd5e25bdea99"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1666\n",
            "{'input_ids': tensor([    0,   720,  3994,  2052, 10428,  2775,   647,  3657,  2119,  1085,\n",
            "            3,     2,   720,  3994,  2052,   911,  2075,  3669,  2119,  3926,\n",
            "         2088,  1513,  2359, 13964,     2,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(3)}\n",
            "[CLS] 18일 귀국이라 발인도 지켜드리지 못해 더욱 죄송할 따름입니다. [SEP] 18일 배를 타고 여행을 떠났습니다. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "output_pred = []\n",
        "output_prob = []\n",
        "\n",
        "for i, data in enumerate(tqdm(dataloader)):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            input_ids=data['input_ids'].to(device),\n",
        "            attention_mask=data['attention_mask'].to(device),\n",
        "            token_type_ids=data['token_type_ids'].to(device)\n",
        "        )\n",
        "    logits = outputs[0]\n",
        "    prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    result = np.argmax(logits, axis=-1)\n",
        "\n",
        "    output_pred.append(result)\n",
        "    output_prob.append(prob)\n",
        "  \n",
        "pred_answer, output_prob = np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()\n",
        "print(pred_answer)"
      ],
      "metadata": {
        "id": "DLTqv229_gRQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "a32c724b8d2641b38968a456883699df",
            "ab01ebf5e42f4a83b9e520e7599f9c51",
            "7aa87784b6be466889f28f486f764624",
            "32c4aea0a4434755a866bfb7cf66bb62",
            "3c2ef487fee24d61a0e216aa31700a05",
            "fcede2396d4e4b21a78a9933b374018b",
            "ccf7e69140794dd2ba35f777fb3dfba4",
            "8790f8a99b874afab714f65786c0d75b",
            "fb630b3c154f4a219a035bc97f4d0de1",
            "1fd22b4521c44d65aec12a77175b32fb",
            "28c9fb80864b49efb24c496822ab320e"
          ]
        },
        "outputId": "9d0701e0-c086-4f85-b8fe-3e21ea0c2aac"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a32c724b8d2641b38968a456883699df",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/105 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 0, 1, 1, 2, 1, 2, 0, 2, 2, 0, 1, 0, 2, 2, 2, 2, 1, 2, 1, 2, 1, 0, 1, 2, 0, 0, 0, 2, 1, 1, 1, 2, 2, 1, 2, 1, 0, 1, 2, 0, 2, 2, 2, 1, 2, 0, 1, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 1, 0, 2, 0, 1, 2, 2, 0, 2, 2, 1, 1, 1, 1, 1, 0, 1, 2, 1, 0, 2, 1, 2, 0, 1, 0, 2, 1, 1, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 1, 0, 1, 2, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 0, 0, 1, 2, 1, 2, 1, 0, 2, 0, 1, 2, 1, 1, 2, 2, 2, 0, 2, 1, 0, 1, 2, 2, 1, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0, 0, 2, 0, 2, 1, 2, 0, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 0, 2, 1, 2, 0, 1, 2, 0, 1, 0, 2, 0, 0, 2, 0, 2, 2, 2, 0, 1, 1, 0, 0, 2, 0, 2, 1, 1, 1, 2, 2, 1, 1, 0, 1, 1, 2, 2, 0, 1, 2, 2, 1, 2, 1, 2, 0, 2, 1, 0, 0, 2, 2, 1, 0, 0, 0, 1, 2, 2, 2, 0, 2, 2, 1, 2, 0, 2, 2, 0, 2, 2, 1, 1, 0, 0, 0, 0, 1, 2, 2, 2, 1, 2, 1, 0, 2, 2, 0, 0, 2, 1, 1, 1, 2, 2, 2, 2, 0, 0, 1, 0, 2, 1, 0, 2, 0, 1, 0, 2, 0, 1, 1, 1, 2, 0, 2, 0, 2, 0, 1, 0, 2, 1, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 1, 1, 1, 2, 1, 1, 2, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 1, 2, 0, 1, 1, 1, 2, 1, 2, 0, 2, 2, 1, 2, 0, 1, 2, 1, 1, 2, 2, 1, 2, 2, 0, 1, 2, 1, 1, 0, 2, 2, 0, 0, 2, 0, 0, 0, 2, 1, 2, 0, 2, 0, 0, 2, 1, 2, 0, 1, 1, 1, 2, 1, 2, 1, 0, 1, 2, 1, 1, 0, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 0, 2, 0, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 1, 2, 2, 0, 1, 2, 1, 0, 0, 1, 1, 0, 2, 1, 2, 1, 0, 0, 1, 2, 2, 1, 1, 2, 0, 2, 1, 2, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 2, 1, 0, 0, 2, 2, 1, 0, 0, 0, 2, 2, 0, 1, 0, 2, 1, 1, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 1, 1, 2, 2, 1, 2, 2, 1, 0, 0, 1, 0, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 0, 1, 2, 1, 0, 2, 0, 2, 1, 0, 0, 0, 2, 1, 2, 2, 1, 1, 1, 2, 2, 0, 2, 0, 0, 2, 1, 0, 0, 0, 0, 0, 1, 0, 2, 1, 1, 1, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 1, 0, 1, 1, 1, 2, 0, 0, 1, 2, 1, 0, 2, 2, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 2, 2, 1, 2, 1, 2, 0, 1, 1, 1, 1, 1, 2, 0, 1, 0, 2, 0, 2, 2, 1, 0, 0, 2, 1, 0, 2, 0, 2, 0, 2, 1, 1, 2, 0, 1, 1, 0, 2, 2, 2, 1, 0, 1, 2, 1, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 1, 2, 0, 2, 2, 1, 1, 2, 1, 0, 1, 2, 1, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 1, 0, 1, 1, 2, 1, 2, 0, 2, 0, 0, 0, 1, 2, 2, 0, 0, 2, 2, 1, 0, 1, 2, 1, 1, 0, 0, 2, 0, 2, 0, 2, 1, 2, 0, 0, 2, 2, 0, 0, 2, 2, 2, 1, 2, 2, 2, 1, 2, 0, 0, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 0, 2, 0, 1, 2, 1, 2, 0, 0, 0, 2, 1, 0, 2, 2, 0, 2, 1, 2, 0, 2, 1, 2, 0, 1, 0, 2, 0, 2, 2, 0, 1, 0, 0, 2, 0, 2, 0, 2, 1, 2, 0, 0, 1, 1, 0, 1, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 1, 2, 1, 0, 0, 1, 1, 0, 2, 0, 2, 1, 2, 1, 2, 0, 1, 0, 2, 2, 1, 1, 0, 2, 2, 1, 0, 2, 1, 0, 0, 2, 1, 0, 1, 0, 1, 2, 2, 0, 0, 2, 1, 2, 1, 2, 0, 0, 2, 1, 0, 1, 2, 2, 2, 1, 1, 0, 0, 1, 2, 2, 0, 2, 0, 1, 0, 0, 1, 2, 0, 2, 0, 2, 2, 1, 0, 0, 0, 2, 1, 1, 1, 0, 2, 2, 2, 0, 2, 2, 1, 1, 2, 0, 2, 0, 0, 0, 2, 1, 0, 0, 0, 0, 2, 0, 2, 2, 1, 1, 0, 1, 0, 1, 0, 0, 1, 2, 2, 0, 0, 2, 2, 0, 1, 2, 1, 1, 1, 0, 2, 0, 1, 1, 2, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 2, 1, 1, 0, 0, 2, 0, 0, 0, 2, 0, 1, 2, 2, 1, 1, 2, 1, 0, 0, 2, 1, 2, 0, 2, 2, 1, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 2, 2, 0, 2, 1, 2, 0, 0, 0, 1, 1, 0, 2, 2, 1, 0, 0, 2, 2, 1, 1, 0, 2, 1, 0, 2, 1, 2, 1, 1, 1, 1, 2, 1, 0, 1, 2, 2, 0, 0, 1, 0, 1, 0, 0, 2, 0, 2, 2, 0, 2, 1, 1, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 2, 0, 1, 0, 2, 1, 0, 2, 1, 1, 1, 1, 1, 2, 0, 1, 2, 0, 2, 1, 1, 2, 2, 0, 2, 2, 1, 0, 1, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 2, 2, 2, 0, 0, 1, 1, 2, 2, 1, 2, 2, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 0, 2, 0, 2, 1, 1, 0, 1, 2, 0, 2, 2, 2, 0, 2, 2, 0, 1, 1, 0, 2, 0, 2, 0, 2, 2, 1, 2, 1, 2, 2, 0, 2, 2, 2, 1, 2, 0, 1, 2, 1, 2, 2, 2, 0, 1, 0, 0, 1, 2, 0, 1, 1, 2, 1, 0, 2, 1, 0, 2, 2, 2, 1, 1, 0, 1, 2, 0, 0, 1, 2, 1, 2, 0, 2, 2, 2, 1, 2, 2, 0, 1, 2, 0, 0, 2, 1, 1, 0, 2, 1, 0, 0, 0, 0, 2, 2, 2, 2, 2, 0, 1, 1, 0, 2, 0, 2, 0, 1, 1, 2, 1, 0, 0, 1, 0, 2, 0, 0, 2, 2, 2, 0, 1, 1, 1, 2, 0, 1, 0, 1, 2, 2, 0, 1, 0, 1, 0, 1, 0, 2, 0, 1, 2, 0, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 0, 2, 2, 2, 1, 2, 0, 1, 2, 1, 1, 2, 1, 2, 0, 0, 2, 1, 0, 0, 2, 1, 1, 2, 0, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 0, 2, 2, 1, 0, 2, 0, 1, 1, 0, 1, 0, 2, 2, 1, 0, 0, 1, 1, 1, 0, 2, 2, 1, 2, 2, 2, 2, 1, 1, 0, 1, 2, 1, 2, 1, 2, 2, 2, 1, 0, 2, 1, 2, 2, 0, 1, 0, 0, 1, 2, 1, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 0, 1, 0, 0, 1, 1, 1, 2, 2, 0, 1, 2, 2, 1, 0, 0, 2, 1, 1, 0, 2, 0, 0, 1, 2, 2, 0, 2, 2, 0, 2, 2, 1, 2, 2, 1, 1, 0, 1, 0, 2, 1, 1, 2, 1, 0, 0, 2, 0, 2, 0, 1, 1, 2, 1, 2, 1, 2, 1, 0, 0, 1, 1, 2, 2, 1, 0, 1, 2, 1, 0, 2, 2, 0, 0, 1, 1, 1, 1, 2, 0, 2, 2, 1, 1, 0, 2, 0, 2, 2, 2, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0, 1, 1, 2, 1, 1, 0, 2, 2, 1, 2, 1, 2, 0, 1, 2, 2, 2, 2, 1, 2, 0, 1, 1, 2, 1, 2, 0, 0, 2, 1, 0, 2, 2, 0, 2, 2, 2, 2, 2, 1, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 2, 2, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 0, 2, 2, 2, 2, 0, 0, 1, 0, 1, 2, 2, 2, 0, 0, 2, 2, 1, 1, 1, 2, 0, 2, 0, 0, 1, 0, 2, 2, 0, 2, 0, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def num_to_label(label):\n",
        "    label_dict = {0: \"entailment\", 1: \"contradiction\", 2: \"neutral\"}\n",
        "    str_label = []\n",
        "\n",
        "    for i, v in enumerate(label):\n",
        "        str_label.append([i,label_dict[v]])\n",
        "    \n",
        "    return str_label\n",
        "\n",
        "answer = num_to_label(pred_answer)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "NABEttQw_h3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2507b64-3282-4725-d2ad-9fe86ceacdab"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 'contradiction'], [1, 'neutral'], [2, 'entailment'], [3, 'contradiction'], [4, 'contradiction'], [5, 'neutral'], [6, 'contradiction'], [7, 'neutral'], [8, 'entailment'], [9, 'neutral'], [10, 'neutral'], [11, 'entailment'], [12, 'contradiction'], [13, 'entailment'], [14, 'neutral'], [15, 'neutral'], [16, 'neutral'], [17, 'neutral'], [18, 'contradiction'], [19, 'neutral'], [20, 'contradiction'], [21, 'neutral'], [22, 'contradiction'], [23, 'entailment'], [24, 'contradiction'], [25, 'neutral'], [26, 'entailment'], [27, 'entailment'], [28, 'entailment'], [29, 'neutral'], [30, 'contradiction'], [31, 'contradiction'], [32, 'contradiction'], [33, 'neutral'], [34, 'neutral'], [35, 'contradiction'], [36, 'neutral'], [37, 'contradiction'], [38, 'entailment'], [39, 'contradiction'], [40, 'neutral'], [41, 'entailment'], [42, 'neutral'], [43, 'neutral'], [44, 'neutral'], [45, 'contradiction'], [46, 'neutral'], [47, 'entailment'], [48, 'contradiction'], [49, 'entailment'], [50, 'neutral'], [51, 'neutral'], [52, 'entailment'], [53, 'neutral'], [54, 'neutral'], [55, 'entailment'], [56, 'neutral'], [57, 'neutral'], [58, 'neutral'], [59, 'neutral'], [60, 'entailment'], [61, 'neutral'], [62, 'neutral'], [63, 'neutral'], [64, 'neutral'], [65, 'contradiction'], [66, 'neutral'], [67, 'neutral'], [68, 'neutral'], [69, 'contradiction'], [70, 'entailment'], [71, 'neutral'], [72, 'entailment'], [73, 'contradiction'], [74, 'neutral'], [75, 'neutral'], [76, 'entailment'], [77, 'neutral'], [78, 'neutral'], [79, 'contradiction'], [80, 'contradiction'], [81, 'contradiction'], [82, 'contradiction'], [83, 'contradiction'], [84, 'entailment'], [85, 'contradiction'], [86, 'neutral'], [87, 'contradiction'], [88, 'entailment'], [89, 'neutral'], [90, 'contradiction'], [91, 'neutral'], [92, 'entailment'], [93, 'contradiction'], [94, 'entailment'], [95, 'neutral'], [96, 'contradiction'], [97, 'contradiction'], [98, 'entailment'], [99, 'neutral'], [100, 'neutral'], [101, 'entailment'], [102, 'neutral'], [103, 'entailment'], [104, 'neutral'], [105, 'entailment'], [106, 'neutral'], [107, 'neutral'], [108, 'contradiction'], [109, 'entailment'], [110, 'contradiction'], [111, 'neutral'], [112, 'contradiction'], [113, 'entailment'], [114, 'neutral'], [115, 'contradiction'], [116, 'contradiction'], [117, 'contradiction'], [118, 'contradiction'], [119, 'contradiction'], [120, 'contradiction'], [121, 'contradiction'], [122, 'contradiction'], [123, 'neutral'], [124, 'neutral'], [125, 'entailment'], [126, 'entailment'], [127, 'entailment'], [128, 'contradiction'], [129, 'neutral'], [130, 'contradiction'], [131, 'neutral'], [132, 'contradiction'], [133, 'entailment'], [134, 'neutral'], [135, 'entailment'], [136, 'contradiction'], [137, 'neutral'], [138, 'contradiction'], [139, 'contradiction'], [140, 'neutral'], [141, 'neutral'], [142, 'neutral'], [143, 'entailment'], [144, 'neutral'], [145, 'contradiction'], [146, 'entailment'], [147, 'contradiction'], [148, 'neutral'], [149, 'neutral'], [150, 'contradiction'], [151, 'entailment'], [152, 'contradiction'], [153, 'neutral'], [154, 'entailment'], [155, 'entailment'], [156, 'entailment'], [157, 'contradiction'], [158, 'neutral'], [159, 'neutral'], [160, 'entailment'], [161, 'entailment'], [162, 'neutral'], [163, 'entailment'], [164, 'neutral'], [165, 'contradiction'], [166, 'neutral'], [167, 'entailment'], [168, 'neutral'], [169, 'entailment'], [170, 'neutral'], [171, 'neutral'], [172, 'contradiction'], [173, 'neutral'], [174, 'neutral'], [175, 'neutral'], [176, 'neutral'], [177, 'neutral'], [178, 'contradiction'], [179, 'neutral'], [180, 'contradiction'], [181, 'neutral'], [182, 'neutral'], [183, 'neutral'], [184, 'entailment'], [185, 'neutral'], [186, 'contradiction'], [187, 'neutral'], [188, 'entailment'], [189, 'contradiction'], [190, 'neutral'], [191, 'entailment'], [192, 'contradiction'], [193, 'entailment'], [194, 'neutral'], [195, 'entailment'], [196, 'entailment'], [197, 'neutral'], [198, 'entailment'], [199, 'neutral'], [200, 'neutral'], [201, 'neutral'], [202, 'entailment'], [203, 'contradiction'], [204, 'contradiction'], [205, 'entailment'], [206, 'entailment'], [207, 'neutral'], [208, 'entailment'], [209, 'neutral'], [210, 'contradiction'], [211, 'contradiction'], [212, 'contradiction'], [213, 'neutral'], [214, 'neutral'], [215, 'contradiction'], [216, 'contradiction'], [217, 'entailment'], [218, 'contradiction'], [219, 'contradiction'], [220, 'neutral'], [221, 'neutral'], [222, 'entailment'], [223, 'contradiction'], [224, 'neutral'], [225, 'neutral'], [226, 'contradiction'], [227, 'neutral'], [228, 'contradiction'], [229, 'neutral'], [230, 'entailment'], [231, 'neutral'], [232, 'contradiction'], [233, 'entailment'], [234, 'entailment'], [235, 'neutral'], [236, 'neutral'], [237, 'contradiction'], [238, 'entailment'], [239, 'entailment'], [240, 'entailment'], [241, 'contradiction'], [242, 'neutral'], [243, 'neutral'], [244, 'neutral'], [245, 'entailment'], [246, 'neutral'], [247, 'neutral'], [248, 'contradiction'], [249, 'neutral'], [250, 'entailment'], [251, 'neutral'], [252, 'neutral'], [253, 'entailment'], [254, 'neutral'], [255, 'neutral'], [256, 'contradiction'], [257, 'contradiction'], [258, 'entailment'], [259, 'entailment'], [260, 'entailment'], [261, 'entailment'], [262, 'contradiction'], [263, 'neutral'], [264, 'neutral'], [265, 'neutral'], [266, 'contradiction'], [267, 'neutral'], [268, 'contradiction'], [269, 'entailment'], [270, 'neutral'], [271, 'neutral'], [272, 'entailment'], [273, 'entailment'], [274, 'neutral'], [275, 'contradiction'], [276, 'contradiction'], [277, 'contradiction'], [278, 'neutral'], [279, 'neutral'], [280, 'neutral'], [281, 'neutral'], [282, 'entailment'], [283, 'entailment'], [284, 'contradiction'], [285, 'entailment'], [286, 'neutral'], [287, 'contradiction'], [288, 'entailment'], [289, 'neutral'], [290, 'entailment'], [291, 'contradiction'], [292, 'entailment'], [293, 'neutral'], [294, 'entailment'], [295, 'contradiction'], [296, 'contradiction'], [297, 'contradiction'], [298, 'neutral'], [299, 'entailment'], [300, 'neutral'], [301, 'entailment'], [302, 'neutral'], [303, 'entailment'], [304, 'contradiction'], [305, 'entailment'], [306, 'neutral'], [307, 'contradiction'], [308, 'entailment'], [309, 'entailment'], [310, 'entailment'], [311, 'contradiction'], [312, 'contradiction'], [313, 'neutral'], [314, 'neutral'], [315, 'neutral'], [316, 'neutral'], [317, 'neutral'], [318, 'neutral'], [319, 'entailment'], [320, 'entailment'], [321, 'neutral'], [322, 'neutral'], [323, 'entailment'], [324, 'contradiction'], [325, 'contradiction'], [326, 'contradiction'], [327, 'neutral'], [328, 'contradiction'], [329, 'contradiction'], [330, 'neutral'], [331, 'entailment'], [332, 'entailment'], [333, 'contradiction'], [334, 'contradiction'], [335, 'contradiction'], [336, 'entailment'], [337, 'contradiction'], [338, 'contradiction'], [339, 'entailment'], [340, 'contradiction'], [341, 'neutral'], [342, 'neutral'], [343, 'contradiction'], [344, 'neutral'], [345, 'entailment'], [346, 'contradiction'], [347, 'contradiction'], [348, 'contradiction'], [349, 'neutral'], [350, 'contradiction'], [351, 'neutral'], [352, 'entailment'], [353, 'neutral'], [354, 'neutral'], [355, 'contradiction'], [356, 'neutral'], [357, 'entailment'], [358, 'contradiction'], [359, 'neutral'], [360, 'contradiction'], [361, 'contradiction'], [362, 'neutral'], [363, 'neutral'], [364, 'contradiction'], [365, 'neutral'], [366, 'neutral'], [367, 'entailment'], [368, 'contradiction'], [369, 'neutral'], [370, 'contradiction'], [371, 'contradiction'], [372, 'entailment'], [373, 'neutral'], [374, 'neutral'], [375, 'entailment'], [376, 'entailment'], [377, 'neutral'], [378, 'entailment'], [379, 'entailment'], [380, 'entailment'], [381, 'neutral'], [382, 'contradiction'], [383, 'neutral'], [384, 'entailment'], [385, 'neutral'], [386, 'entailment'], [387, 'entailment'], [388, 'neutral'], [389, 'contradiction'], [390, 'neutral'], [391, 'entailment'], [392, 'contradiction'], [393, 'contradiction'], [394, 'contradiction'], [395, 'neutral'], [396, 'contradiction'], [397, 'neutral'], [398, 'contradiction'], [399, 'entailment'], [400, 'contradiction'], [401, 'neutral'], [402, 'contradiction'], [403, 'contradiction'], [404, 'entailment'], [405, 'neutral'], [406, 'contradiction'], [407, 'neutral'], [408, 'contradiction'], [409, 'neutral'], [410, 'contradiction'], [411, 'contradiction'], [412, 'contradiction'], [413, 'contradiction'], [414, 'neutral'], [415, 'contradiction'], [416, 'contradiction'], [417, 'contradiction'], [418, 'neutral'], [419, 'contradiction'], [420, 'neutral'], [421, 'neutral'], [422, 'entailment'], [423, 'neutral'], [424, 'entailment'], [425, 'neutral'], [426, 'neutral'], [427, 'contradiction'], [428, 'contradiction'], [429, 'contradiction'], [430, 'entailment'], [431, 'neutral'], [432, 'contradiction'], [433, 'neutral'], [434, 'entailment'], [435, 'neutral'], [436, 'entailment'], [437, 'entailment'], [438, 'entailment'], [439, 'entailment'], [440, 'entailment'], [441, 'contradiction'], [442, 'entailment'], [443, 'neutral'], [444, 'contradiction'], [445, 'neutral'], [446, 'neutral'], [447, 'entailment'], [448, 'contradiction'], [449, 'neutral'], [450, 'contradiction'], [451, 'entailment'], [452, 'entailment'], [453, 'contradiction'], [454, 'contradiction'], [455, 'entailment'], [456, 'neutral'], [457, 'contradiction'], [458, 'neutral'], [459, 'contradiction'], [460, 'entailment'], [461, 'entailment'], [462, 'contradiction'], [463, 'neutral'], [464, 'neutral'], [465, 'contradiction'], [466, 'contradiction'], [467, 'neutral'], [468, 'entailment'], [469, 'neutral'], [470, 'contradiction'], [471, 'neutral'], [472, 'entailment'], [473, 'entailment'], [474, 'entailment'], [475, 'neutral'], [476, 'entailment'], [477, 'contradiction'], [478, 'entailment'], [479, 'contradiction'], [480, 'entailment'], [481, 'entailment'], [482, 'contradiction'], [483, 'entailment'], [484, 'neutral'], [485, 'entailment'], [486, 'entailment'], [487, 'neutral'], [488, 'contradiction'], [489, 'entailment'], [490, 'entailment'], [491, 'neutral'], [492, 'neutral'], [493, 'contradiction'], [494, 'entailment'], [495, 'entailment'], [496, 'entailment'], [497, 'neutral'], [498, 'neutral'], [499, 'entailment'], [500, 'contradiction'], [501, 'entailment'], [502, 'neutral'], [503, 'contradiction'], [504, 'contradiction'], [505, 'entailment'], [506, 'entailment'], [507, 'contradiction'], [508, 'entailment'], [509, 'contradiction'], [510, 'neutral'], [511, 'entailment'], [512, 'entailment'], [513, 'entailment'], [514, 'entailment'], [515, 'contradiction'], [516, 'entailment'], [517, 'entailment'], [518, 'contradiction'], [519, 'contradiction'], [520, 'neutral'], [521, 'neutral'], [522, 'contradiction'], [523, 'neutral'], [524, 'neutral'], [525, 'contradiction'], [526, 'entailment'], [527, 'entailment'], [528, 'contradiction'], [529, 'entailment'], [530, 'neutral'], [531, 'neutral'], [532, 'contradiction'], [533, 'neutral'], [534, 'neutral'], [535, 'contradiction'], [536, 'contradiction'], [537, 'contradiction'], [538, 'neutral'], [539, 'neutral'], [540, 'neutral'], [541, 'contradiction'], [542, 'contradiction'], [543, 'entailment'], [544, 'contradiction'], [545, 'neutral'], [546, 'contradiction'], [547, 'entailment'], [548, 'neutral'], [549, 'entailment'], [550, 'neutral'], [551, 'contradiction'], [552, 'entailment'], [553, 'entailment'], [554, 'entailment'], [555, 'neutral'], [556, 'contradiction'], [557, 'neutral'], [558, 'neutral'], [559, 'contradiction'], [560, 'contradiction'], [561, 'contradiction'], [562, 'neutral'], [563, 'neutral'], [564, 'entailment'], [565, 'neutral'], [566, 'entailment'], [567, 'entailment'], [568, 'neutral'], [569, 'contradiction'], [570, 'entailment'], [571, 'entailment'], [572, 'entailment'], [573, 'entailment'], [574, 'entailment'], [575, 'contradiction'], [576, 'entailment'], [577, 'neutral'], [578, 'contradiction'], [579, 'contradiction'], [580, 'contradiction'], [581, 'entailment'], [582, 'entailment'], [583, 'neutral'], [584, 'entailment'], [585, 'entailment'], [586, 'neutral'], [587, 'entailment'], [588, 'neutral'], [589, 'entailment'], [590, 'entailment'], [591, 'neutral'], [592, 'contradiction'], [593, 'entailment'], [594, 'contradiction'], [595, 'contradiction'], [596, 'contradiction'], [597, 'neutral'], [598, 'entailment'], [599, 'entailment'], [600, 'contradiction'], [601, 'neutral'], [602, 'contradiction'], [603, 'entailment'], [604, 'neutral'], [605, 'neutral'], [606, 'contradiction'], [607, 'contradiction'], [608, 'contradiction'], [609, 'contradiction'], [610, 'contradiction'], [611, 'entailment'], [612, 'neutral'], [613, 'entailment'], [614, 'contradiction'], [615, 'contradiction'], [616, 'neutral'], [617, 'neutral'], [618, 'contradiction'], [619, 'neutral'], [620, 'contradiction'], [621, 'neutral'], [622, 'entailment'], [623, 'contradiction'], [624, 'contradiction'], [625, 'contradiction'], [626, 'contradiction'], [627, 'contradiction'], [628, 'neutral'], [629, 'entailment'], [630, 'contradiction'], [631, 'entailment'], [632, 'neutral'], [633, 'entailment'], [634, 'neutral'], [635, 'neutral'], [636, 'contradiction'], [637, 'entailment'], [638, 'entailment'], [639, 'neutral'], [640, 'contradiction'], [641, 'entailment'], [642, 'neutral'], [643, 'entailment'], [644, 'neutral'], [645, 'entailment'], [646, 'neutral'], [647, 'contradiction'], [648, 'contradiction'], [649, 'neutral'], [650, 'entailment'], [651, 'contradiction'], [652, 'contradiction'], [653, 'entailment'], [654, 'neutral'], [655, 'neutral'], [656, 'neutral'], [657, 'contradiction'], [658, 'entailment'], [659, 'contradiction'], [660, 'neutral'], [661, 'contradiction'], [662, 'neutral'], [663, 'neutral'], [664, 'neutral'], [665, 'entailment'], [666, 'neutral'], [667, 'entailment'], [668, 'neutral'], [669, 'neutral'], [670, 'neutral'], [671, 'neutral'], [672, 'neutral'], [673, 'contradiction'], [674, 'neutral'], [675, 'entailment'], [676, 'neutral'], [677, 'neutral'], [678, 'contradiction'], [679, 'contradiction'], [680, 'neutral'], [681, 'contradiction'], [682, 'entailment'], [683, 'contradiction'], [684, 'neutral'], [685, 'contradiction'], [686, 'neutral'], [687, 'neutral'], [688, 'entailment'], [689, 'entailment'], [690, 'neutral'], [691, 'entailment'], [692, 'entailment'], [693, 'neutral'], [694, 'entailment'], [695, 'entailment'], [696, 'entailment'], [697, 'contradiction'], [698, 'entailment'], [699, 'entailment'], [700, 'contradiction'], [701, 'entailment'], [702, 'entailment'], [703, 'neutral'], [704, 'contradiction'], [705, 'entailment'], [706, 'contradiction'], [707, 'contradiction'], [708, 'neutral'], [709, 'contradiction'], [710, 'neutral'], [711, 'entailment'], [712, 'neutral'], [713, 'entailment'], [714, 'entailment'], [715, 'entailment'], [716, 'contradiction'], [717, 'neutral'], [718, 'neutral'], [719, 'entailment'], [720, 'entailment'], [721, 'neutral'], [722, 'neutral'], [723, 'contradiction'], [724, 'entailment'], [725, 'contradiction'], [726, 'neutral'], [727, 'contradiction'], [728, 'contradiction'], [729, 'entailment'], [730, 'entailment'], [731, 'neutral'], [732, 'entailment'], [733, 'neutral'], [734, 'entailment'], [735, 'neutral'], [736, 'contradiction'], [737, 'neutral'], [738, 'entailment'], [739, 'entailment'], [740, 'neutral'], [741, 'neutral'], [742, 'entailment'], [743, 'entailment'], [744, 'neutral'], [745, 'neutral'], [746, 'neutral'], [747, 'contradiction'], [748, 'neutral'], [749, 'neutral'], [750, 'neutral'], [751, 'contradiction'], [752, 'neutral'], [753, 'entailment'], [754, 'entailment'], [755, 'neutral'], [756, 'entailment'], [757, 'contradiction'], [758, 'neutral'], [759, 'neutral'], [760, 'entailment'], [761, 'neutral'], [762, 'entailment'], [763, 'contradiction'], [764, 'neutral'], [765, 'entailment'], [766, 'neutral'], [767, 'entailment'], [768, 'contradiction'], [769, 'neutral'], [770, 'contradiction'], [771, 'neutral'], [772, 'entailment'], [773, 'entailment'], [774, 'entailment'], [775, 'neutral'], [776, 'contradiction'], [777, 'entailment'], [778, 'neutral'], [779, 'neutral'], [780, 'entailment'], [781, 'neutral'], [782, 'contradiction'], [783, 'neutral'], [784, 'entailment'], [785, 'neutral'], [786, 'contradiction'], [787, 'neutral'], [788, 'entailment'], [789, 'contradiction'], [790, 'entailment'], [791, 'neutral'], [792, 'entailment'], [793, 'neutral'], [794, 'neutral'], [795, 'entailment'], [796, 'contradiction'], [797, 'entailment'], [798, 'entailment'], [799, 'neutral'], [800, 'entailment'], [801, 'neutral'], [802, 'entailment'], [803, 'neutral'], [804, 'contradiction'], [805, 'neutral'], [806, 'entailment'], [807, 'entailment'], [808, 'contradiction'], [809, 'contradiction'], [810, 'entailment'], [811, 'contradiction'], [812, 'contradiction'], [813, 'neutral'], [814, 'neutral'], [815, 'neutral'], [816, 'neutral'], [817, 'neutral'], [818, 'neutral'], [819, 'entailment'], [820, 'neutral'], [821, 'neutral'], [822, 'neutral'], [823, 'neutral'], [824, 'neutral'], [825, 'neutral'], [826, 'contradiction'], [827, 'neutral'], [828, 'contradiction'], [829, 'entailment'], [830, 'entailment'], [831, 'contradiction'], [832, 'contradiction'], [833, 'entailment'], [834, 'neutral'], [835, 'entailment'], [836, 'neutral'], [837, 'contradiction'], [838, 'neutral'], [839, 'contradiction'], [840, 'neutral'], [841, 'entailment'], [842, 'contradiction'], [843, 'entailment'], [844, 'neutral'], [845, 'neutral'], [846, 'contradiction'], [847, 'contradiction'], [848, 'entailment'], [849, 'neutral'], [850, 'neutral'], [851, 'contradiction'], [852, 'entailment'], [853, 'neutral'], [854, 'contradiction'], [855, 'entailment'], [856, 'entailment'], [857, 'neutral'], [858, 'contradiction'], [859, 'entailment'], [860, 'contradiction'], [861, 'entailment'], [862, 'contradiction'], [863, 'neutral'], [864, 'neutral'], [865, 'entailment'], [866, 'entailment'], [867, 'neutral'], [868, 'contradiction'], [869, 'neutral'], [870, 'contradiction'], [871, 'neutral'], [872, 'entailment'], [873, 'entailment'], [874, 'neutral'], [875, 'contradiction'], [876, 'entailment'], [877, 'contradiction'], [878, 'neutral'], [879, 'neutral'], [880, 'neutral'], [881, 'contradiction'], [882, 'contradiction'], [883, 'entailment'], [884, 'entailment'], [885, 'contradiction'], [886, 'neutral'], [887, 'neutral'], [888, 'entailment'], [889, 'neutral'], [890, 'entailment'], [891, 'contradiction'], [892, 'entailment'], [893, 'entailment'], [894, 'contradiction'], [895, 'neutral'], [896, 'entailment'], [897, 'neutral'], [898, 'entailment'], [899, 'neutral'], [900, 'neutral'], [901, 'contradiction'], [902, 'entailment'], [903, 'entailment'], [904, 'entailment'], [905, 'neutral'], [906, 'contradiction'], [907, 'contradiction'], [908, 'contradiction'], [909, 'entailment'], [910, 'neutral'], [911, 'neutral'], [912, 'neutral'], [913, 'entailment'], [914, 'neutral'], [915, 'neutral'], [916, 'contradiction'], [917, 'contradiction'], [918, 'neutral'], [919, 'entailment'], [920, 'neutral'], [921, 'entailment'], [922, 'entailment'], [923, 'entailment'], [924, 'neutral'], [925, 'contradiction'], [926, 'entailment'], [927, 'entailment'], [928, 'entailment'], [929, 'entailment'], [930, 'neutral'], [931, 'entailment'], [932, 'neutral'], [933, 'neutral'], [934, 'contradiction'], [935, 'contradiction'], [936, 'entailment'], [937, 'contradiction'], [938, 'entailment'], [939, 'contradiction'], [940, 'entailment'], [941, 'entailment'], [942, 'contradiction'], [943, 'neutral'], [944, 'neutral'], [945, 'entailment'], [946, 'entailment'], [947, 'neutral'], [948, 'neutral'], [949, 'entailment'], [950, 'contradiction'], [951, 'neutral'], [952, 'contradiction'], [953, 'contradiction'], [954, 'contradiction'], [955, 'entailment'], [956, 'neutral'], [957, 'entailment'], [958, 'contradiction'], [959, 'contradiction'], [960, 'neutral'], [961, 'contradiction'], [962, 'contradiction'], [963, 'contradiction'], [964, 'entailment'], [965, 'entailment'], [966, 'contradiction'], [967, 'entailment'], [968, 'entailment'], [969, 'contradiction'], [970, 'entailment'], [971, 'entailment'], [972, 'neutral'], [973, 'contradiction'], [974, 'contradiction'], [975, 'entailment'], [976, 'entailment'], [977, 'neutral'], [978, 'entailment'], [979, 'entailment'], [980, 'entailment'], [981, 'neutral'], [982, 'entailment'], [983, 'contradiction'], [984, 'neutral'], [985, 'neutral'], [986, 'contradiction'], [987, 'contradiction'], [988, 'neutral'], [989, 'contradiction'], [990, 'entailment'], [991, 'entailment'], [992, 'neutral'], [993, 'contradiction'], [994, 'neutral'], [995, 'entailment'], [996, 'neutral'], [997, 'neutral'], [998, 'contradiction'], [999, 'entailment'], [1000, 'entailment'], [1001, 'entailment'], [1002, 'contradiction'], [1003, 'entailment'], [1004, 'neutral'], [1005, 'entailment'], [1006, 'entailment'], [1007, 'entailment'], [1008, 'neutral'], [1009, 'neutral'], [1010, 'neutral'], [1011, 'entailment'], [1012, 'neutral'], [1013, 'contradiction'], [1014, 'neutral'], [1015, 'entailment'], [1016, 'entailment'], [1017, 'entailment'], [1018, 'contradiction'], [1019, 'contradiction'], [1020, 'entailment'], [1021, 'neutral'], [1022, 'neutral'], [1023, 'contradiction'], [1024, 'entailment'], [1025, 'entailment'], [1026, 'neutral'], [1027, 'neutral'], [1028, 'contradiction'], [1029, 'contradiction'], [1030, 'entailment'], [1031, 'neutral'], [1032, 'contradiction'], [1033, 'entailment'], [1034, 'neutral'], [1035, 'contradiction'], [1036, 'neutral'], [1037, 'contradiction'], [1038, 'contradiction'], [1039, 'contradiction'], [1040, 'contradiction'], [1041, 'neutral'], [1042, 'contradiction'], [1043, 'entailment'], [1044, 'contradiction'], [1045, 'neutral'], [1046, 'neutral'], [1047, 'entailment'], [1048, 'entailment'], [1049, 'contradiction'], [1050, 'entailment'], [1051, 'contradiction'], [1052, 'entailment'], [1053, 'entailment'], [1054, 'neutral'], [1055, 'entailment'], [1056, 'neutral'], [1057, 'neutral'], [1058, 'entailment'], [1059, 'neutral'], [1060, 'contradiction'], [1061, 'contradiction'], [1062, 'contradiction'], [1063, 'entailment'], [1064, 'entailment'], [1065, 'neutral'], [1066, 'entailment'], [1067, 'entailment'], [1068, 'entailment'], [1069, 'neutral'], [1070, 'entailment'], [1071, 'entailment'], [1072, 'neutral'], [1073, 'neutral'], [1074, 'entailment'], [1075, 'contradiction'], [1076, 'entailment'], [1077, 'neutral'], [1078, 'contradiction'], [1079, 'entailment'], [1080, 'neutral'], [1081, 'contradiction'], [1082, 'contradiction'], [1083, 'contradiction'], [1084, 'contradiction'], [1085, 'contradiction'], [1086, 'neutral'], [1087, 'entailment'], [1088, 'contradiction'], [1089, 'neutral'], [1090, 'entailment'], [1091, 'neutral'], [1092, 'contradiction'], [1093, 'contradiction'], [1094, 'neutral'], [1095, 'neutral'], [1096, 'entailment'], [1097, 'neutral'], [1098, 'neutral'], [1099, 'contradiction'], [1100, 'entailment'], [1101, 'contradiction'], [1102, 'neutral'], [1103, 'entailment'], [1104, 'contradiction'], [1105, 'entailment'], [1106, 'contradiction'], [1107, 'contradiction'], [1108, 'entailment'], [1109, 'contradiction'], [1110, 'contradiction'], [1111, 'contradiction'], [1112, 'contradiction'], [1113, 'contradiction'], [1114, 'neutral'], [1115, 'neutral'], [1116, 'neutral'], [1117, 'entailment'], [1118, 'entailment'], [1119, 'contradiction'], [1120, 'contradiction'], [1121, 'neutral'], [1122, 'neutral'], [1123, 'contradiction'], [1124, 'neutral'], [1125, 'neutral'], [1126, 'entailment'], [1127, 'contradiction'], [1128, 'entailment'], [1129, 'contradiction'], [1130, 'entailment'], [1131, 'entailment'], [1132, 'entailment'], [1133, 'contradiction'], [1134, 'contradiction'], [1135, 'contradiction'], [1136, 'contradiction'], [1137, 'contradiction'], [1138, 'contradiction'], [1139, 'entailment'], [1140, 'neutral'], [1141, 'contradiction'], [1142, 'contradiction'], [1143, 'contradiction'], [1144, 'entailment'], [1145, 'neutral'], [1146, 'entailment'], [1147, 'neutral'], [1148, 'contradiction'], [1149, 'contradiction'], [1150, 'entailment'], [1151, 'contradiction'], [1152, 'neutral'], [1153, 'entailment'], [1154, 'neutral'], [1155, 'neutral'], [1156, 'neutral'], [1157, 'entailment'], [1158, 'neutral'], [1159, 'neutral'], [1160, 'entailment'], [1161, 'contradiction'], [1162, 'contradiction'], [1163, 'entailment'], [1164, 'neutral'], [1165, 'entailment'], [1166, 'neutral'], [1167, 'entailment'], [1168, 'neutral'], [1169, 'neutral'], [1170, 'contradiction'], [1171, 'neutral'], [1172, 'contradiction'], [1173, 'neutral'], [1174, 'neutral'], [1175, 'entailment'], [1176, 'neutral'], [1177, 'neutral'], [1178, 'neutral'], [1179, 'contradiction'], [1180, 'neutral'], [1181, 'entailment'], [1182, 'contradiction'], [1183, 'neutral'], [1184, 'contradiction'], [1185, 'neutral'], [1186, 'neutral'], [1187, 'neutral'], [1188, 'entailment'], [1189, 'contradiction'], [1190, 'entailment'], [1191, 'entailment'], [1192, 'contradiction'], [1193, 'neutral'], [1194, 'entailment'], [1195, 'contradiction'], [1196, 'contradiction'], [1197, 'neutral'], [1198, 'contradiction'], [1199, 'entailment'], [1200, 'neutral'], [1201, 'contradiction'], [1202, 'entailment'], [1203, 'neutral'], [1204, 'neutral'], [1205, 'neutral'], [1206, 'contradiction'], [1207, 'contradiction'], [1208, 'entailment'], [1209, 'contradiction'], [1210, 'neutral'], [1211, 'entailment'], [1212, 'entailment'], [1213, 'contradiction'], [1214, 'neutral'], [1215, 'contradiction'], [1216, 'neutral'], [1217, 'entailment'], [1218, 'neutral'], [1219, 'neutral'], [1220, 'neutral'], [1221, 'contradiction'], [1222, 'neutral'], [1223, 'neutral'], [1224, 'entailment'], [1225, 'contradiction'], [1226, 'neutral'], [1227, 'entailment'], [1228, 'entailment'], [1229, 'neutral'], [1230, 'contradiction'], [1231, 'contradiction'], [1232, 'entailment'], [1233, 'neutral'], [1234, 'contradiction'], [1235, 'entailment'], [1236, 'entailment'], [1237, 'entailment'], [1238, 'entailment'], [1239, 'neutral'], [1240, 'neutral'], [1241, 'neutral'], [1242, 'neutral'], [1243, 'neutral'], [1244, 'entailment'], [1245, 'contradiction'], [1246, 'contradiction'], [1247, 'entailment'], [1248, 'neutral'], [1249, 'entailment'], [1250, 'neutral'], [1251, 'entailment'], [1252, 'contradiction'], [1253, 'contradiction'], [1254, 'neutral'], [1255, 'contradiction'], [1256, 'entailment'], [1257, 'entailment'], [1258, 'contradiction'], [1259, 'entailment'], [1260, 'neutral'], [1261, 'entailment'], [1262, 'entailment'], [1263, 'neutral'], [1264, 'neutral'], [1265, 'neutral'], [1266, 'entailment'], [1267, 'contradiction'], [1268, 'contradiction'], [1269, 'contradiction'], [1270, 'neutral'], [1271, 'entailment'], [1272, 'contradiction'], [1273, 'entailment'], [1274, 'contradiction'], [1275, 'neutral'], [1276, 'neutral'], [1277, 'entailment'], [1278, 'contradiction'], [1279, 'entailment'], [1280, 'contradiction'], [1281, 'entailment'], [1282, 'contradiction'], [1283, 'entailment'], [1284, 'neutral'], [1285, 'entailment'], [1286, 'contradiction'], [1287, 'neutral'], [1288, 'entailment'], [1289, 'neutral'], [1290, 'neutral'], [1291, 'neutral'], [1292, 'neutral'], [1293, 'neutral'], [1294, 'neutral'], [1295, 'contradiction'], [1296, 'contradiction'], [1297, 'neutral'], [1298, 'contradiction'], [1299, 'neutral'], [1300, 'contradiction'], [1301, 'contradiction'], [1302, 'entailment'], [1303, 'neutral'], [1304, 'neutral'], [1305, 'neutral'], [1306, 'contradiction'], [1307, 'neutral'], [1308, 'entailment'], [1309, 'contradiction'], [1310, 'neutral'], [1311, 'contradiction'], [1312, 'contradiction'], [1313, 'neutral'], [1314, 'contradiction'], [1315, 'neutral'], [1316, 'entailment'], [1317, 'entailment'], [1318, 'neutral'], [1319, 'contradiction'], [1320, 'entailment'], [1321, 'entailment'], [1322, 'neutral'], [1323, 'contradiction'], [1324, 'contradiction'], [1325, 'neutral'], [1326, 'entailment'], [1327, 'neutral'], [1328, 'neutral'], [1329, 'contradiction'], [1330, 'neutral'], [1331, 'neutral'], [1332, 'contradiction'], [1333, 'neutral'], [1334, 'contradiction'], [1335, 'neutral'], [1336, 'contradiction'], [1337, 'neutral'], [1338, 'entailment'], [1339, 'neutral'], [1340, 'neutral'], [1341, 'contradiction'], [1342, 'entailment'], [1343, 'neutral'], [1344, 'entailment'], [1345, 'contradiction'], [1346, 'contradiction'], [1347, 'entailment'], [1348, 'contradiction'], [1349, 'entailment'], [1350, 'neutral'], [1351, 'neutral'], [1352, 'contradiction'], [1353, 'entailment'], [1354, 'entailment'], [1355, 'contradiction'], [1356, 'contradiction'], [1357, 'contradiction'], [1358, 'entailment'], [1359, 'neutral'], [1360, 'neutral'], [1361, 'contradiction'], [1362, 'neutral'], [1363, 'neutral'], [1364, 'neutral'], [1365, 'neutral'], [1366, 'contradiction'], [1367, 'contradiction'], [1368, 'entailment'], [1369, 'contradiction'], [1370, 'neutral'], [1371, 'contradiction'], [1372, 'neutral'], [1373, 'contradiction'], [1374, 'neutral'], [1375, 'neutral'], [1376, 'neutral'], [1377, 'contradiction'], [1378, 'entailment'], [1379, 'neutral'], [1380, 'contradiction'], [1381, 'neutral'], [1382, 'neutral'], [1383, 'entailment'], [1384, 'contradiction'], [1385, 'entailment'], [1386, 'entailment'], [1387, 'contradiction'], [1388, 'neutral'], [1389, 'contradiction'], [1390, 'entailment'], [1391, 'entailment'], [1392, 'neutral'], [1393, 'entailment'], [1394, 'entailment'], [1395, 'neutral'], [1396, 'entailment'], [1397, 'neutral'], [1398, 'entailment'], [1399, 'neutral'], [1400, 'neutral'], [1401, 'neutral'], [1402, 'entailment'], [1403, 'entailment'], [1404, 'entailment'], [1405, 'contradiction'], [1406, 'entailment'], [1407, 'entailment'], [1408, 'contradiction'], [1409, 'contradiction'], [1410, 'contradiction'], [1411, 'neutral'], [1412, 'neutral'], [1413, 'entailment'], [1414, 'contradiction'], [1415, 'neutral'], [1416, 'neutral'], [1417, 'contradiction'], [1418, 'entailment'], [1419, 'entailment'], [1420, 'neutral'], [1421, 'contradiction'], [1422, 'contradiction'], [1423, 'entailment'], [1424, 'neutral'], [1425, 'entailment'], [1426, 'entailment'], [1427, 'contradiction'], [1428, 'neutral'], [1429, 'neutral'], [1430, 'entailment'], [1431, 'neutral'], [1432, 'neutral'], [1433, 'entailment'], [1434, 'neutral'], [1435, 'neutral'], [1436, 'contradiction'], [1437, 'neutral'], [1438, 'neutral'], [1439, 'contradiction'], [1440, 'contradiction'], [1441, 'entailment'], [1442, 'contradiction'], [1443, 'entailment'], [1444, 'neutral'], [1445, 'contradiction'], [1446, 'contradiction'], [1447, 'neutral'], [1448, 'contradiction'], [1449, 'entailment'], [1450, 'entailment'], [1451, 'neutral'], [1452, 'entailment'], [1453, 'neutral'], [1454, 'entailment'], [1455, 'contradiction'], [1456, 'contradiction'], [1457, 'neutral'], [1458, 'contradiction'], [1459, 'neutral'], [1460, 'contradiction'], [1461, 'neutral'], [1462, 'contradiction'], [1463, 'entailment'], [1464, 'entailment'], [1465, 'contradiction'], [1466, 'contradiction'], [1467, 'neutral'], [1468, 'neutral'], [1469, 'contradiction'], [1470, 'entailment'], [1471, 'contradiction'], [1472, 'neutral'], [1473, 'contradiction'], [1474, 'entailment'], [1475, 'neutral'], [1476, 'neutral'], [1477, 'entailment'], [1478, 'entailment'], [1479, 'contradiction'], [1480, 'contradiction'], [1481, 'contradiction'], [1482, 'contradiction'], [1483, 'neutral'], [1484, 'entailment'], [1485, 'neutral'], [1486, 'neutral'], [1487, 'contradiction'], [1488, 'contradiction'], [1489, 'entailment'], [1490, 'neutral'], [1491, 'entailment'], [1492, 'neutral'], [1493, 'neutral'], [1494, 'neutral'], [1495, 'entailment'], [1496, 'contradiction'], [1497, 'contradiction'], [1498, 'entailment'], [1499, 'contradiction'], [1500, 'contradiction'], [1501, 'entailment'], [1502, 'entailment'], [1503, 'entailment'], [1504, 'contradiction'], [1505, 'entailment'], [1506, 'entailment'], [1507, 'entailment'], [1508, 'neutral'], [1509, 'neutral'], [1510, 'entailment'], [1511, 'contradiction'], [1512, 'contradiction'], [1513, 'neutral'], [1514, 'contradiction'], [1515, 'contradiction'], [1516, 'entailment'], [1517, 'neutral'], [1518, 'neutral'], [1519, 'contradiction'], [1520, 'neutral'], [1521, 'contradiction'], [1522, 'neutral'], [1523, 'entailment'], [1524, 'contradiction'], [1525, 'neutral'], [1526, 'neutral'], [1527, 'neutral'], [1528, 'neutral'], [1529, 'contradiction'], [1530, 'neutral'], [1531, 'entailment'], [1532, 'contradiction'], [1533, 'contradiction'], [1534, 'neutral'], [1535, 'contradiction'], [1536, 'neutral'], [1537, 'entailment'], [1538, 'entailment'], [1539, 'neutral'], [1540, 'contradiction'], [1541, 'entailment'], [1542, 'neutral'], [1543, 'neutral'], [1544, 'entailment'], [1545, 'neutral'], [1546, 'neutral'], [1547, 'neutral'], [1548, 'neutral'], [1549, 'neutral'], [1550, 'contradiction'], [1551, 'entailment'], [1552, 'neutral'], [1553, 'entailment'], [1554, 'neutral'], [1555, 'neutral'], [1556, 'entailment'], [1557, 'neutral'], [1558, 'entailment'], [1559, 'entailment'], [1560, 'neutral'], [1561, 'entailment'], [1562, 'neutral'], [1563, 'neutral'], [1564, 'contradiction'], [1565, 'entailment'], [1566, 'contradiction'], [1567, 'entailment'], [1568, 'entailment'], [1569, 'contradiction'], [1570, 'entailment'], [1571, 'contradiction'], [1572, 'entailment'], [1573, 'contradiction'], [1574, 'contradiction'], [1575, 'contradiction'], [1576, 'neutral'], [1577, 'contradiction'], [1578, 'neutral'], [1579, 'contradiction'], [1580, 'neutral'], [1581, 'contradiction'], [1582, 'contradiction'], [1583, 'entailment'], [1584, 'neutral'], [1585, 'neutral'], [1586, 'neutral'], [1587, 'neutral'], [1588, 'entailment'], [1589, 'entailment'], [1590, 'contradiction'], [1591, 'entailment'], [1592, 'contradiction'], [1593, 'neutral'], [1594, 'neutral'], [1595, 'neutral'], [1596, 'entailment'], [1597, 'entailment'], [1598, 'neutral'], [1599, 'neutral'], [1600, 'contradiction'], [1601, 'contradiction'], [1602, 'contradiction'], [1603, 'neutral'], [1604, 'entailment'], [1605, 'neutral'], [1606, 'entailment'], [1607, 'entailment'], [1608, 'contradiction'], [1609, 'entailment'], [1610, 'neutral'], [1611, 'neutral'], [1612, 'entailment'], [1613, 'neutral'], [1614, 'entailment'], [1615, 'contradiction'], [1616, 'neutral'], [1617, 'neutral'], [1618, 'neutral'], [1619, 'contradiction'], [1620, 'neutral'], [1621, 'contradiction'], [1622, 'contradiction'], [1623, 'neutral'], [1624, 'contradiction'], [1625, 'neutral'], [1626, 'neutral'], [1627, 'entailment'], [1628, 'contradiction'], [1629, 'neutral'], [1630, 'contradiction'], [1631, 'entailment'], [1632, 'entailment'], [1633, 'entailment'], [1634, 'entailment'], [1635, 'neutral'], [1636, 'entailment'], [1637, 'contradiction'], [1638, 'contradiction'], [1639, 'entailment'], [1640, 'entailment'], [1641, 'entailment'], [1642, 'entailment'], [1643, 'entailment'], [1644, 'contradiction'], [1645, 'neutral'], [1646, 'contradiction'], [1647, 'entailment'], [1648, 'entailment'], [1649, 'contradiction'], [1650, 'contradiction'], [1651, 'entailment'], [1652, 'entailment'], [1653, 'contradiction'], [1654, 'contradiction'], [1655, 'entailment'], [1656, 'neutral'], [1657, 'contradiction'], [1658, 'neutral'], [1659, 'neutral'], [1660, 'entailment'], [1661, 'neutral'], [1662, 'neutral'], [1663, 'neutral'], [1664, 'neutral'], [1665, 'neutral']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(answer, columns=['index', 'label'])\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/KLUE/submission.csv', index=False)\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "6rV5-ld6_i74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b21dd46-df20-429b-fa0b-c890b61a9f57"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      index          label\n",
            "0         0  contradiction\n",
            "1         1        neutral\n",
            "2         2     entailment\n",
            "3         3  contradiction\n",
            "4         4  contradiction\n",
            "...     ...            ...\n",
            "1661   1661        neutral\n",
            "1662   1662        neutral\n",
            "1663   1663        neutral\n",
            "1664   1664        neutral\n",
            "1665   1665        neutral\n",
            "\n",
            "[1666 rows x 2 columns]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "A full training",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "91de12c8cb3e4875b22a75feefd5a2e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1bb3e2a2bfce4926bdc84ff16353c7b9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b7f023d007ca4b37b2bc416534745179",
              "IPY_MODEL_df5954de8b61444abc29e550ec9284b9",
              "IPY_MODEL_6dc628f645af470fa7469c2075120319"
            ]
          }
        },
        "1bb3e2a2bfce4926bdc84ff16353c7b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b7f023d007ca4b37b2bc416534745179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b98b4b18ad6742ac998540a8890f8d63",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f02a89beb44a4ff1bb2c48040804bf46"
          }
        },
        "df5954de8b61444abc29e550ec9284b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6c112873eaa04cc19a5c5a9a48abc4c0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 7820,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7820,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc51853a2f4f4b31a86e7a7534663725"
          }
        },
        "6dc628f645af470fa7469c2075120319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ac48f81c7d6f414986e27369d82d9e24",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7820/7820 [2:13:25&lt;00:00,  1.33it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00df1b6abce74e2fa4028f7604aa51e0"
          }
        },
        "b98b4b18ad6742ac998540a8890f8d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f02a89beb44a4ff1bb2c48040804bf46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c112873eaa04cc19a5c5a9a48abc4c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc51853a2f4f4b31a86e7a7534663725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac48f81c7d6f414986e27369d82d9e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00df1b6abce74e2fa4028f7604aa51e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a32c724b8d2641b38968a456883699df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ab01ebf5e42f4a83b9e520e7599f9c51",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7aa87784b6be466889f28f486f764624",
              "IPY_MODEL_32c4aea0a4434755a866bfb7cf66bb62",
              "IPY_MODEL_3c2ef487fee24d61a0e216aa31700a05"
            ]
          }
        },
        "ab01ebf5e42f4a83b9e520e7599f9c51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7aa87784b6be466889f28f486f764624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fcede2396d4e4b21a78a9933b374018b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ccf7e69140794dd2ba35f777fb3dfba4"
          }
        },
        "32c4aea0a4434755a866bfb7cf66bb62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8790f8a99b874afab714f65786c0d75b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 105,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 105,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb630b3c154f4a219a035bc97f4d0de1"
          }
        },
        "3c2ef487fee24d61a0e216aa31700a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1fd22b4521c44d65aec12a77175b32fb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 105/105 [00:15&lt;00:00,  6.80it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_28c9fb80864b49efb24c496822ab320e"
          }
        },
        "fcede2396d4e4b21a78a9933b374018b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ccf7e69140794dd2ba35f777fb3dfba4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8790f8a99b874afab714f65786c0d75b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb630b3c154f4a219a035bc97f4d0de1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fd22b4521c44d65aec12a77175b32fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "28c9fb80864b49efb24c496822ab320e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}