{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teamgaon/KLUE/blob/main/220215_sm_roberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYbZ60DFIibf"
      },
      "source": [
        "# KoBERT finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 특허문서의 title, abstract, claim과 산업분류 코드를 활용하여 IPC를 예측"
      ],
      "metadata": {
        "id": "xTzWUoeUiYIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install gluonnlp\n",
        "# !pip install mxnet\n",
        "# !pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n",
        "# # !pip install git+https://git@github.com/SKTBrain/KoBERT.git@master\n",
        "# !pip install transformers\n",
        "# !pip install sentencepiece\n",
        "# !pip install kobert-transformers\n",
        "# !pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "metadata": {
        "id": "tK31HdsHJi6-",
        "outputId": "7408974f-ceaa-412e-8c67-6275f3e20ff3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gluonnlp\n",
            "  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 35.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 20.1 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 40 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 92 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 245 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 256 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 266 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 276 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 286 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 296 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 307 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 317 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 327 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 337 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 344 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.27)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.7)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595736 sha256=0e97bd2ea0945e0f44d755ecad76649e98ae4912ecaf8f0cd580df60c1216c92\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.10.0\n",
            "Collecting mxnet\n",
            "  Downloading mxnet-1.9.0-py3-none-manylinux2014_x86_64.whl (47.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.3 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.9.0\n",
            "Collecting kobert_tokenizer\n",
            "  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-hatd7x3b/kobert-tokenizer_42c4befec0534657b0bfba863062ad83\n",
            "  Running command git clone -q https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-hatd7x3b/kobert-tokenizer_42c4befec0534657b0bfba863062ad83\n",
            "Building wheels for collected packages: kobert-tokenizer\n",
            "  Building wheel for kobert-tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert-tokenizer: filename=kobert_tokenizer-0.1-py3-none-any.whl size=4649 sha256=ee05e5034b032d516adee66668de11fb52305f9c0594a60bc08719a433a14388\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-96msvwsp/wheels/10/b4/d9/cb627bbfaefa266657b0b4e8127f7bf96d27376fa1a23897b4\n",
            "Successfully built kobert-tokenizer\n",
            "Installing collected packages: kobert-tokenizer\n",
            "Successfully installed kobert-tokenizer-0.1\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 51.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 88.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 91.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.2\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Collecting kobert-transformers\n",
            "  Downloading kobert_transformers-0.5.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from kobert-transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: transformers<5,>=3 in /usr/local/lib/python3.7/dist-packages (from kobert-transformers) (4.16.2)\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.7/dist-packages (from kobert-transformers) (0.1.96)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->kobert-transformers) (3.10.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (3.4.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (4.10.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (0.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (0.11.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (0.0.47)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (4.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5,>=3->kobert-transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5,>=3->kobert-transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5,>=3->kobert-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5,>=3->kobert-transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5,>=3->kobert-transformers) (1.15.0)\n",
            "Installing collected packages: kobert-transformers\n",
            "Successfully installed kobert-transformers-0.5.1\n",
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-fjidq447\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-fjidq447\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.21.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gluonnlp>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.10.0)\n",
            "Requirement already satisfied: mxnet>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.9.0)\n",
            "Collecting onnxruntime==1.8.0\n",
            "  Downloading onnxruntime-1.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 39.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sentencepiece>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.1.96)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.10.0+cu111)\n",
            "Requirement already satisfied: transformers>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (4.16.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (1.19.5)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.2.3) (21.3)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.2.3) (0.29.27)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet>=1.4.0->kobert==0.2.3) (0.8.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet>=1.4.0->kobert==0.2.3) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->kobert==0.2.3) (3.10.0.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (4.10.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (0.0.47)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (4.62.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (0.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (3.4.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (0.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp>=0.6.0->kobert==0.2.3) (3.0.7)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting botocore<1.25.0,>=1.24.0\n",
            "  Downloading botocore-1.24.0-py3-none-any.whl (8.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.5 MB 64.3 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.1-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.0->boto3->kobert==0.2.3) (2.8.2)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 91.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.0->boto3->kobert==0.2.3) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.8.1->kobert==0.2.3) (3.7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.8.1->kobert==0.2.3) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.8.1->kobert==0.2.3) (7.1.2)\n",
            "Building wheels for collected packages: kobert\n",
            "  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert: filename=kobert-0.2.3-py3-none-any.whl size=15449 sha256=512434bea38d5b1202b0ba4e3f3a36986929dc28ee87e4abb1aa8508cb7df401\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3miyqb6k/wheels/d3/68/ca/334747dfb038313b49cf71f84832a33372f3470d9ddfd051c0\n",
            "Successfully built kobert\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, onnxruntime, boto3, kobert\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.21.0 botocore-1.24.0 jmespath-0.10.0 kobert-0.2.3 onnxruntime-1.8.0 s3transfer-0.5.1 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gluonnlp\n",
        "!pip install mxnet\n",
        "# !pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n",
        "# !pip install git+https://git@github.com/SKTBrain/KoBERT.git@master\n",
        "!pip install transformers==3.0.2\n",
        "!pip install sentencepiece\n",
        "!pip install kobert-transformers\n",
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpWbKUevj0B1",
        "outputId": "ee5dcb4b-666c-4095-a745-aecdabb283db"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gluonnlp in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.27)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.7)\n",
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.7/dist-packages (1.9.0)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.25.11)\n",
            "Collecting transformers==3.0.2\n",
            "  Using cached transformers-3.0.2-py3-none-any.whl (769 kB)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.1.96)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.0.47)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "  Using cached tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.62.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (3.0.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.11.4\n",
            "    Uninstalling tokenizers-0.11.4:\n",
            "      Successfully uninstalled tokenizers-0.11.4\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.16.2\n",
            "    Uninstalling transformers-4.16.2:\n",
            "      Successfully uninstalled transformers-4.16.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kobert 0.2.3 requires transformers>=4.8.1, but you have transformers 3.0.2 which is incompatible.\u001b[0m\n",
            "Successfully installed tokenizers-0.8.1rc1 transformers-3.0.2\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: kobert-transformers in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: transformers<5,>=3 in /usr/local/lib/python3.7/dist-packages (from kobert-transformers) (3.0.2)\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.7/dist-packages (from kobert-transformers) (0.1.96)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from kobert-transformers) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->kobert-transformers) (3.10.0.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (0.0.47)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (3.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (4.62.3)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (0.8.1rc1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=3->kobert-transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5,>=3->kobert-transformers) (3.0.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5,>=3->kobert-transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5,>=3->kobert-transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5,>=3->kobert-transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5,>=3->kobert-transformers) (1.1.0)\n",
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-ke5yyd6w\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-ke5yyd6w\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.21.0)\n",
            "Requirement already satisfied: gluonnlp>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.10.0)\n",
            "Requirement already satisfied: mxnet>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.9.0)\n",
            "Requirement already satisfied: onnxruntime==1.8.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.8.0)\n",
            "Requirement already satisfied: sentencepiece>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.1.96)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.10.0+cu111)\n",
            "Collecting transformers>=4.8.1\n",
            "  Using cached transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (1.19.5)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (3.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.2.3) (21.3)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.2.3) (0.29.27)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet>=1.4.0->kobert==0.2.3) (2.23.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet>=1.4.0->kobert==0.2.3) (0.8.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (2021.10.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->kobert==0.2.3) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (3.4.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (4.10.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (0.4.0)\n",
            "Collecting tokenizers!=0.11.3,>=0.10.1\n",
            "  Using cached tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (4.62.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (0.0.47)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (2019.12.20)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp>=0.6.0->kobert==0.2.3) (3.0.7)\n",
            "Requirement already satisfied: botocore<1.25.0,>=1.24.0 in /usr/local/lib/python3.7/dist-packages (from boto3->kobert==0.2.3) (1.24.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->kobert==0.2.3) (0.5.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->kobert==0.2.3) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.0->boto3->kobert==0.2.3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.0->boto3->kobert==0.2.3) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.8.1->kobert==0.2.3) (3.7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.8.1->kobert==0.2.3) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.8.1->kobert==0.2.3) (7.1.2)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.8.1rc1\n",
            "    Uninstalling tokenizers-0.8.1rc1:\n",
            "      Successfully uninstalled tokenizers-0.8.1rc1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 3.0.2\n",
            "    Uninstalling transformers-3.0.2:\n",
            "      Successfully uninstalled transformers-3.0.2\n",
            "Successfully installed tokenizers-0.11.4 transformers-4.16.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DZQ9T121Iibk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "# from kobert.utils import get_tokenizer\n",
        "# from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n",
        "# from kobert_tokenizer import KoBERTTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from kobert_transformers import get_tokenizer\n",
        "from kobert_transformers import get_kobert_model, get_distilkobert_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kobert import get_pytorch_kobert_model"
      ],
      "metadata": {
        "id": "z--GqKg_lG3S"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from kobert_transformers import get_tokenizer\n",
        "# tokenizer = get_tokenizer()"
      ],
      "metadata": {
        "id": "b8-bMncuWMG3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
        "\n",
        "# model = AutoModel.from_pretrained(\"klue/roberta-large\")\n",
        "# # tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-large\")\n",
        "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")\n",
        "\n",
        "MODEL_NAME = 'klue/roberta-large'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
        "config.num_labels = 3\n",
        "\n",
        "model = AutoModel.from_pretrained(MODEL_NAME, config=config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMl5S9wOLRL3",
        "outputId": "7ae83ba5-5fae-4ba2-c897-f567da520b39"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/.cache/kobert_v1.zip\n",
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "alMTagtMLaSR",
        "outputId": "ac9876da-9aa8-4d00-ffaa-ddbe0e793e9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/KLUE/train_data.csv')"
      ],
      "metadata": {
        "id": "gvOWIs7yLV3e"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wksUPNuBL8sN",
        "outputId": "83a21be9-90ef-4df4-d5c1-c3fbbe5540de"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c6b5e9ee-9674-4b33-9aa9-91382998961f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서, 소년이나 장정들이...</td>\n",
              "      <td>씨름의 여자들의 놀이이다.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나,...</td>\n",
              "      <td>자작극을 벌인 이는 3명이다.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다.</td>\n",
              "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
              "      <td>원주민들은 종합대책에 만족했다.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면, 이런 상황에서는...</td>\n",
              "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24993</th>\n",
              "      <td>24993</td>\n",
              "      <td>오페라에 비하여 오라토리오에서는 독창보다도 합창이 중시되며, 테스토 또는 이스토리쿠...</td>\n",
              "      <td>오라토리오에서 테스토의 역할이 가장 중요하다.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24994</th>\n",
              "      <td>24994</td>\n",
              "      <td>지하철역까지 걸어서 5분 정도 걸립니다.</td>\n",
              "      <td>지하철역까지 도보로 5분 정도 걸립니다.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>24995</td>\n",
              "      <td>한편 이날 중앙방역대책본부는 집단 감염이 발생한 음식점 관련 역학조사 결과를 공개했다.</td>\n",
              "      <td>중악방역대책본부는 집단 감염과 관련한 모든 정보를 비공개했다.</td>\n",
              "      <td>contradiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>24996</td>\n",
              "      <td>마미손이 랩을 하자 시청자들은 그의 정체를 파악했다.</td>\n",
              "      <td>시청자들은 마미손의 정체를 안다.</td>\n",
              "      <td>entailment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>24997</td>\n",
              "      <td>집근처에 지하철역,버스정류장이 있기때문에 다른 곳으로 이동하는데 좋았습니다.</td>\n",
              "      <td>집 근처에 있는 지하철역을 이용하기 위해서는 걸어서 5분 정도 가야합니다.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24998 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6b5e9ee-9674-4b33-9aa9-91382998961f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6b5e9ee-9674-4b33-9aa9-91382998961f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6b5e9ee-9674-4b33-9aa9-91382998961f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       index  ...          label\n",
              "0          0  ...  contradiction\n",
              "1          1  ...  contradiction\n",
              "2          2  ...     entailment\n",
              "3          3  ...        neutral\n",
              "4          4  ...        neutral\n",
              "...      ...  ...            ...\n",
              "24993  24993  ...        neutral\n",
              "24994  24994  ...     entailment\n",
              "24995  24995  ...  contradiction\n",
              "24996  24996  ...     entailment\n",
              "24997  24997  ...        neutral\n",
              "\n",
              "[24998 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['premise'] = df['premise'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]', '')\n",
        "df['hypothesis'] = df['hypothesis'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 0-9]', '')"
      ],
      "metadata": {
        "id": "mktSnv77tIUW",
        "outputId": "71fa0964-8746-4193-d7e3-1a20c32a7209",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = '[CLS]' + df['premise'] + '[SEP] ' + df['hypothesis'] + '[SEP]'"
      ],
      "metadata": {
        "id": "e7_Mya6dROy4"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "UWz-fIArRbEI",
        "outputId": "e2cb5748-dca5-447e-d20b-07eb8822979c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5faa0f9f-2645-4ed9-8abf-4d9c9e42f4ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 ...</td>\n",
              "      <td>씨름의 여자들의 놀이이다</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>[CLS]씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나 ...</td>\n",
              "      <td>자작극을 벌인 이는 3명이다</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>[CLS]삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다</td>\n",
              "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다</td>\n",
              "      <td>entailment</td>\n",
              "      <td>[CLS]이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다[SEP] 예측적 범...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
              "      <td>원주민들은 종합대책에 만족했다</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[CLS]광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에서는 ...</td>\n",
              "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[CLS]진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24993</th>\n",
              "      <td>24993</td>\n",
              "      <td>오페라에 비하여 오라토리오에서는 독창보다도 합창이 중시되며 테스토 또는 이스토리쿠스...</td>\n",
              "      <td>오라토리오에서 테스토의 역할이 가장 중요하다</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[CLS]오페라에 비하여 오라토리오에서는 독창보다도 합창이 중시되며 테스토 또는 이...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24994</th>\n",
              "      <td>24994</td>\n",
              "      <td>지하철역까지 걸어서 5분 정도 걸립니다</td>\n",
              "      <td>지하철역까지 도보로 5분 정도 걸립니다</td>\n",
              "      <td>entailment</td>\n",
              "      <td>[CLS]지하철역까지 걸어서 5분 정도 걸립니다[SEP] 지하철역까지 도보로 5분 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>24995</td>\n",
              "      <td>한편 이날 중앙방역대책본부는 집단 감염이 발생한 음식점 관련 역학조사 결과를 공개했다</td>\n",
              "      <td>중악방역대책본부는 집단 감염과 관련한 모든 정보를 비공개했다</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>[CLS]한편 이날 중앙방역대책본부는 집단 감염이 발생한 음식점 관련 역학조사 결과...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>24996</td>\n",
              "      <td>마미손이 랩을 하자 시청자들은 그의 정체를 파악했다</td>\n",
              "      <td>시청자들은 마미손의 정체를 안다</td>\n",
              "      <td>entailment</td>\n",
              "      <td>[CLS]마미손이 랩을 하자 시청자들은 그의 정체를 파악했다[SEP] 시청자들은 마...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>24997</td>\n",
              "      <td>집근처에 지하철역버스정류장이 있기때문에 다른 곳으로 이동하는데 좋았습니다</td>\n",
              "      <td>집 근처에 있는 지하철역을 이용하기 위해서는 걸어서 5분 정도 가야합니다</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[CLS]집근처에 지하철역버스정류장이 있기때문에 다른 곳으로 이동하는데 좋았습니다[...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24998 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5faa0f9f-2645-4ed9-8abf-4d9c9e42f4ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5faa0f9f-2645-4ed9-8abf-4d9c9e42f4ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5faa0f9f-2645-4ed9-8abf-4d9c9e42f4ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       index  ...                                               text\n",
              "0          0  ...  [CLS]씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 ...\n",
              "1          1  ...  [CLS]삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 ...\n",
              "2          2  ...  [CLS]이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다[SEP] 예측적 범...\n",
              "3          3  ...  [CLS]광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민...\n",
              "4          4  ...  [CLS]진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상...\n",
              "...      ...  ...                                                ...\n",
              "24993  24993  ...  [CLS]오페라에 비하여 오라토리오에서는 독창보다도 합창이 중시되며 테스토 또는 이...\n",
              "24994  24994  ...  [CLS]지하철역까지 걸어서 5분 정도 걸립니다[SEP] 지하철역까지 도보로 5분 ...\n",
              "24995  24995  ...  [CLS]한편 이날 중앙방역대책본부는 집단 감염이 발생한 음식점 관련 역학조사 결과...\n",
              "24996  24996  ...  [CLS]마미손이 랩을 하자 시청자들은 그의 정체를 파악했다[SEP] 시청자들은 마...\n",
              "24997  24997  ...  [CLS]집근처에 지하철역버스정류장이 있기때문에 다른 곳으로 이동하는데 좋았습니다[...\n",
              "\n",
              "[24998 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_dict={}\n",
        "for i in range(len(df['label'].unique())):\n",
        "  my_dict[df['label'].unique()[i]] = i\n",
        "\n",
        "def label_to_num(text:str):\n",
        "  return my_dict[text]\n",
        "\n",
        "df['target'] = df['label'].map(label_to_num)"
      ],
      "metadata": {
        "id": "IVEc5GgcR1HQ"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "AVWL3GuUSXFV",
        "outputId": "b7a98eb0-c641-444c-fe6e-2b677b2673ea"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-22dac2a9-ba40-4383-8fb9-7658b41c300d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 ...</td>\n",
              "      <td>씨름의 여자들의 놀이이다</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>[CLS]씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나 ...</td>\n",
              "      <td>자작극을 벌인 이는 3명이다</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>[CLS]삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다</td>\n",
              "      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다</td>\n",
              "      <td>entailment</td>\n",
              "      <td>[CLS]이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다[SEP] 예측적 범...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>\n",
              "      <td>원주민들은 종합대책에 만족했다</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[CLS]광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상황에서는 ...</td>\n",
              "      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[CLS]진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면 이런 상...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24993</th>\n",
              "      <td>24993</td>\n",
              "      <td>오페라에 비하여 오라토리오에서는 독창보다도 합창이 중시되며 테스토 또는 이스토리쿠스...</td>\n",
              "      <td>오라토리오에서 테스토의 역할이 가장 중요하다</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[CLS]오페라에 비하여 오라토리오에서는 독창보다도 합창이 중시되며 테스토 또는 이...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24994</th>\n",
              "      <td>24994</td>\n",
              "      <td>지하철역까지 걸어서 5분 정도 걸립니다</td>\n",
              "      <td>지하철역까지 도보로 5분 정도 걸립니다</td>\n",
              "      <td>entailment</td>\n",
              "      <td>[CLS]지하철역까지 걸어서 5분 정도 걸립니다[SEP] 지하철역까지 도보로 5분 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>24995</td>\n",
              "      <td>한편 이날 중앙방역대책본부는 집단 감염이 발생한 음식점 관련 역학조사 결과를 공개했다</td>\n",
              "      <td>중악방역대책본부는 집단 감염과 관련한 모든 정보를 비공개했다</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>[CLS]한편 이날 중앙방역대책본부는 집단 감염이 발생한 음식점 관련 역학조사 결과...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>24996</td>\n",
              "      <td>마미손이 랩을 하자 시청자들은 그의 정체를 파악했다</td>\n",
              "      <td>시청자들은 마미손의 정체를 안다</td>\n",
              "      <td>entailment</td>\n",
              "      <td>[CLS]마미손이 랩을 하자 시청자들은 그의 정체를 파악했다[SEP] 시청자들은 마...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>24997</td>\n",
              "      <td>집근처에 지하철역버스정류장이 있기때문에 다른 곳으로 이동하는데 좋았습니다</td>\n",
              "      <td>집 근처에 있는 지하철역을 이용하기 위해서는 걸어서 5분 정도 가야합니다</td>\n",
              "      <td>neutral</td>\n",
              "      <td>[CLS]집근처에 지하철역버스정류장이 있기때문에 다른 곳으로 이동하는데 좋았습니다[...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24998 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22dac2a9-ba40-4383-8fb9-7658b41c300d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22dac2a9-ba40-4383-8fb9-7658b41c300d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22dac2a9-ba40-4383-8fb9-7658b41c300d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       index  ... target\n",
              "0          0  ...      0\n",
              "1          1  ...      0\n",
              "2          2  ...      1\n",
              "3          3  ...      2\n",
              "4          4  ...      2\n",
              "...      ...  ...    ...\n",
              "24993  24993  ...      2\n",
              "24994  24994  ...      1\n",
              "24995  24995  ...      0\n",
              "24996  24996  ...      1\n",
              "24997  24997  ...      2\n",
              "\n",
              "[24998 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODfiAAZwSNZ3",
        "outputId": "c77f2c42-6148-4eea-f2fa-cc3a1bf83ac3"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'contradiction': 0, 'entailment': 1, 'neutral': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "M0Ncy5XrIibm"
      },
      "outputs": [],
      "source": [
        "## CPU\n",
        "# device = torch.device(\"cpu\")\n",
        "\n",
        "## GPU\n",
        "device = torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_enter(text:str):\n",
        "  return text.replace('\\n',\"\")\n",
        "\n",
        "df['text'] = df['text'].map(remove_enter)"
      ],
      "metadata": {
        "id": "-MiSNubkc0RW"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'].loc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "v09U0rlKow0F",
        "outputId": "5ebc844f-56ee-4866-ca14-1781ec8d1456"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS]씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서 소년이나 장정들이 넓고 평평한 백사장이나 마당에서 모여 서로 힘과 슬기를 겨루는 것이다[SEP] 씨름의 여자들의 놀이이다[SEP]'"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].astype('str')"
      ],
      "metadata": {
        "id": "CuGZoaSEW9bK"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "Iy1Oi2miIibo"
      },
      "outputs": [],
      "source": [
        "# dataset_train = df[['No.', 'text', 'target_label']][:int(len(df)*0.8)]\n",
        "# dataset_test = df[['No.', 'text', 'target_label']][int(len(df)*0.8):]\n",
        "dataset_train, dataset_test = train_test_split(df[['index', 'text', 'target']], test_size=0.2, random_state=42, shuffle=True)\n",
        "dataset_train.to_csv('dataset_train.txt', index=False, header=True, sep='\\t', encoding='utf8')\n",
        "dataset_test.to_csv('dataset_test.txt', index=False, header=True, sep='\\t', encoding='utf8')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = nlp.data.TSVDataset('/content/dataset_train.txt', field_indices=[1,2], num_discard_samples=1)\n",
        "dataset_test = nlp.data.TSVDataset('/content/dataset_test.txt', field_indices=[1,2], num_discard_samples=1)"
      ],
      "metadata": {
        "id": "vPJ7E0GAHuwI"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axsQ1TVvS13w",
        "outputId": "07ab18df-b030-4644-a16b-679c146e5d0c"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['[CLS]강인호는 기간제 교사로 일하게 되어 전라북도의 영화 속의 도시 무진으로 내려가게 된다[SEP] 강인호는 기간제 교사 일때문에 무진으로 내려간다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]이후 스토리상에서 주어지는 미션을 완료하면 된다[SEP] 스토리상에서만 미션이 주어진다[SEP]', '2'],\n",
              " ['[CLS]기상청 관계자는 특히 동해안지방은 동풍류 유입에 의한 지형적인 영향으로 많은 비가 오는 곳이 있을 것이라고 말했다[SEP] 동해안지방은 비나 눈이 오는 곳이 있을 것이라고 말했다[SEP]',\n",
              "  '0'],\n",
              " ['[CLS]조안의 연기는 작품을 거듭할수록 진보하는듯[SEP] 조안의 초기 연기는 출중하지 않았는 듯[SEP]', '2'],\n",
              " ['[CLS]코즈웨이베이역이랑 5분거리인것도 좋앗습니다[SEP] 5분거리에 코즈웨이베이역이 있습니다[SEP]', '1'],\n",
              " ['[CLS]평생을 가족에게 헌신한 평범한 주부 김광자는 다가오는 생일에 대한 부푼 꿈을 꾸고 있지만 막상 그날이 되었지만 가족들은 그녀의 생일을 기억하지도 못한다[SEP] 김광자의 친구들은 그녀의 생일을 축하해주었다[SEP]',\n",
              "  '2'],\n",
              " ['[CLS]미국 최대의 초콜릿 제조업체인 허쉬 역시 코트 디부아르 뿐 아니라 서 아프리카 지역에 몇 개의 카카오 농장을 운영하고 있습니다[SEP] 허쉬의 카카오 농장이 전세계에서 가장 크다[SEP]',\n",
              "  '2'],\n",
              " ['[CLS]귀신이 나온다는 괴담이 돌며 실제 체험을 위해 방문했던 사람들이 실종되었다는 곤지암 정신병원에 남녀 7인으로 이루어진 체험단이 방문한다[SEP] 곤지암 정신병원에는 귀신이 나온다는 괴담이 돌았다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]호기심가득 견자단 연기 몰입감 있어요[SEP] 견자단의 액션연기는 몰입감있어요[SEP]', '2'],\n",
              " ['[CLS]예고편에서 김요한 연습생은 트레이너들 앞에서 노래를 부르다 가사를 잊는 실수를 했다[SEP] 예고편에서는 김요한 연습생이 나오지 않았다[SEP]',\n",
              "  '0'],\n",
              " ['[CLS]인종차별과 불평등은 미국만의 문제가 아니다[SEP] 미국만이 불평등과 인종차별의 문제를 가지고 있는 것은 아니다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]교통도 편하고 근처에 슈퍼도 가까워요[SEP] 슈퍼는 매우 멀리 떨어져 있어요[SEP]', '0'],\n",
              " ['[CLS]중국의 어느 시골길에서 한 청년이 2시간 가까이 기다려 44번 버스를 탄다[SEP] 중국의 시골길에는 44번 버스만 다닌다[SEP]',\n",
              "  '2'],\n",
              " ['[CLS]세탁기에 빨래건조대까지 모든게 다 있었습니다[SEP] 빨래건조대와 세탁기가 존재했습니다[SEP]', '1'],\n",
              " ['[CLS]지하에는 슈퍼마켓있는데 펑리슈 40원합니다[SEP] 지하 슈퍼마켓에는 펑리슈를 40원에 팝니다[SEP]', '1'],\n",
              " ['[CLS]깔끔하고 지하철역과 가까운 좋은 숙소입니다[SEP] 숙소에서 지하철역까지는 멉니다[SEP]', '0'],\n",
              " ['[CLS]새롭게 시작하는 제21대 국회가 국민의 어려움을 덜어드리고 희망을 줄 수 있는 장이 되기를 기대합니다[SEP] 국민들의 많은 관심이 있어야 제21대 국회도 제역할을 할 수 있습니다[SEP]',\n",
              "  '2'],\n",
              " ['[CLS]미닛맨은 미국 독립 전쟁에서 활약했던 민병을 가리킨다[SEP] 미국 독립 전쟁에 민병들도 참여했다[SEP]', '1'],\n",
              " ['[CLS]이번 유럽 여행중 가장 맘에들던 숙소였어요[SEP] 이번 유럽 여행중 가장 형편없는 숙소였어요[SEP]', '0'],\n",
              " ['[CLS]대한민국 정부는 미사일 발사에 기술적인 문제가 발생하였을 것으로 추측하고 있으며 기상조건의 영향을 받았을 수도 있다고 보고 있다[SEP] 정부는 미사일 발사에 기술적인 문제는없었을거라 추측하고 있다[SEP]',\n",
              "  '0'],\n",
              " ['[CLS]머무르는 동안 너무 만족했던 공간이었습니다[SEP] 너무 맘에 들었던 공간이었습니다[SEP]', '1'],\n",
              " ['[CLS]매력적인 시나리오와 배우들의 연기도 매우 좋았다[SEP] 모든 주연 배우와 조연 배우의 연기가 좋았다[SEP]', '2'],\n",
              " ['[CLS]다음 파리일정때 또 머물고 싶은 숙소에요[SEP] 다시는 머물고 싶지 않은 숙소에요[SEP]', '0'],\n",
              " ['[CLS]무엇보다도 호스트의 친절함이 너무 좋았습니다[SEP] 호스트는 팁을 많이 주는 손님에게만 친절했습니다[SEP]', '2'],\n",
              " ['[CLS]타국 사례와 비교해서 이승만 정부의 친일 청산이 상대적으로 잘 이뤄졌음을 밝히고 있다[SEP] 문재인 정부의 친일 청산만 잘 이뤄졌음을 밝히고 있다[SEP]',\n",
              "  '0'],\n",
              " ['[CLS]현미경이 발명되고 미시적인 대상을 관찰할 수 있게 되어서야 비로소 세포를 발견할 수 있었다[SEP] 현미경이 발명되기 전에도 세포를 관찰할 수 있었다[SEP]',\n",
              "  '0'],\n",
              " ['[CLS]부산 양덕여중에 범람한 물이 쓸려와 학생과 교직원 400여명이 고립되었다가 구조되었고 곳곳에서 산사태도 속출했습니다[SEP] 곳곳에서 산사태가 속출해 인근 도로를 통제 중이다[SEP]',\n",
              "  '2'],\n",
              " ['[CLS]시작부터 마지막까지 눈을 돌릴수없게 만드는 영화 배우들이 연기와 좋은 각본이 빛을 발한다[SEP] 화려한  덕에 영화에서 눈을 돌릴 수가 없었다[SEP]',\n",
              "  '0'],\n",
              " ['[CLS]아기자기한 소품이 많은 복층 에어비앤비였습니다[SEP] 복층 구조가 아기자기 했습니다[SEP]', '2'],\n",
              " ['[CLS]이번 교육은 각 업무별 자치법규 정비 담당자들을 대상으로 자치법규 입안 실무 교육을 통해 법제업무 능력을 향상시키기 위해 마련됐다[SEP] 실무 교육은 업무 능력 향상과 무관하다[SEP]',\n",
              "  '0'],\n",
              " ['[CLS]사업지 인근으로 미55 보급창 공원화사업 부산항 해양산업 클러스터 개발 계획 등이 예정돼 있다[SEP] 부산항 해양산업 클러스터 지역을 없앨 계획이다[SEP]',\n",
              "  '0'],\n",
              " ['[CLS]안식향 성분은 사람의 신경을 안정시키고 우울증 치료에도 도움을 준다[SEP] 안식향은 신경을 안정시키고 우울증 치료에 유익하다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]집주인과의 첫만남은 아직 비행중인 시간에일방적으로개인적인일로 미팅시간을 뒤로 미룬다는 메일을 보내왔다[SEP] 집주인은 나에게 메일을 보낸 적이 있다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]같이 일을 하다 죽은 친구의 외동딸을 찾으러 영국으로 온 그는 얼굴도 모르는 친구의 딸을 찾던 중 옆집 다락방에 살고 있는 세라를 알게 된다[SEP] 그는 자신의 딸을 찾으로 영국에 왔다[SEP]',\n",
              "  '0'],\n",
              " ['[CLS]현재 23만여 명의 구독자를 보유하고 있으며 월요일부터 금요일까지 주 5일 뉴스레터 서비스를 하고 있다[SEP] 현재 구독자 수는 약 23만 명이다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]사람들 반응 보니까 후반부 안 보길 잘한 듯[SEP] 후반부를 보지 않아 다행인 듯[SEP]', '1'],\n",
              " ['[CLS]이들은 특히 환자에 대한 친절한 태도와 높은 의료수준을 보유한 한국을 선호하고 있다[SEP] 이들은 높은 의료수준을 보유한 일본도 선호하고 있다[SEP]',\n",
              "  '2'],\n",
              " ['[CLS]편리한 위치 넓은 방 내부시설 다 좋았다[SEP] 내부시설이 넓었다[SEP]', '2'],\n",
              " ['[CLS]군은 소규모 시설원예 농가의 하우스 필름과 천장 개폐시설 지원 등 낡은 시설 하우스를 현대화하기 위해 군비 3억 원을 확보했다[SEP] 군전체의 시설원예 하우스 시설이 개선되었다[SEP]',\n",
              "  '2'],\n",
              " ['[CLS]이는 대외무역법상의 전략물자 수출 허가 절차 전기통신사업법 전파법 우주개발진흥법상 절차를 무시한 불법이라는 주장이다[SEP] 대외무역법상의 전략물자 수출 허가 절차를 무시한 불법이라는 세계무역기구의 주장이다[SEP]',\n",
              "  '2'],\n",
              " ['[CLS]일드 별로 안좋아하지만 이것만은 적극추천해요[SEP] 일드 엄청 좋아해서 이건 적극 추천해요[SEP]', '0'],\n",
              " ['[CLS]무엇보다 이 건물이 로케이션이 좋습니다[SEP] 이 건물의 위치가 좋습니다[SEP]', '1'],\n",
              " ['[CLS]아니스 샤리프는 카다피를 발견한 곳을 언급하지 않았지만 카다피는 여전히 리비아에 있으며 고급 기술과 인지를 사용하여 그를 추적하였다고 말했다[SEP] 카다피는 리비아 수도 근처 구멍가게에서 발견되었다[SEP]',\n",
              "  '2'],\n",
              " ['[CLS]어머니와 함께하는 여행이기때문에 이런 상황이 난감했습니다[SEP] 여행을 어머니와 함께 했습니다[SEP]', '1'],\n",
              " ['[CLS]스트레스를 해소하는 데에는 이보다 좋은 영화가 없다[SEP] 스트레스 해소하기에 제일 별로인 영화이다[SEP]', '0'],\n",
              " ['[CLS]주방 공간도 넓어서 요리하는데 편리해요[SEP] 주방 공간이 너무 좁아요[SEP]', '0'],\n",
              " ['[CLS]출연진은 중학교 3학년이라는 의뢰인 나이에 맞게 각자 어버이날 선물을 추천했다[SEP] 출연진은 의뢰인을 위해 본인들이 준비한 선물을 주었다[SEP]',\n",
              "  '0'],\n",
              " ['[CLS]또한 2023년부터 금융투자소득을 도입해 주식형 펀드의 이익과 상장주식 양도차익을 합산하고 기본공제금액을 당초 2000만원에서 5000만원으로 높게 설정했다[SEP] 금융투자소득을 2023년 1분기에 도입한다[SEP]',\n",
              "  '2'],\n",
              " ['[CLS]학교 및 유치원은 방역 수칙을 준수하며 등교 수업과 원격 수업을 병행 실시한다[SEP] 학원도 방역 수칙을 준수합니다[SEP]',\n",
              "  '2'],\n",
              " ['[CLS]아울러 문제가 지적된 정수장은 23일까지 보완조치를 완료하고 그 사항을 환경부에 보고하도록 조치했다[SEP] 문제가 지적된 정수장은 30일까지 환경부에 보고하도록 조치했다[SEP]',\n",
              "  '0'],\n",
              " ['[CLS]세월호 특별법때문에 막힌 정국을 풀기 위한 회의조차 파행으로 끝났고 광화문에서는 아직도 유가족들이 농성하고 있습니다[SEP] 세월호 특별법때문에 막힌 정국을 풀기 위한 회의가 열렸습니다[SEP]',\n",
              "  '0'],\n",
              " ['[CLS]물통이 닿지 않아 물을 못 먹었거나 다른 이유로 물을 못 먹은 말은 심하게 머리를 흔들어대거나 입술을 핥아댄다[SEP] 물을 못 먹은 말이 보이는 증상은 머리를 흔드는 것 뿐이다[SEP]',\n",
              "  '0'],\n",
              " ['[CLS]보통영화와 다른 특별한 분위기와 독특함에 반했다[SEP] 보통영화와 차별화된 특별한 분위기와 독특함에 반했다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]수소택시 부제 면제 신규허가가 가능한 수소 화물차의 톤급 범위 확대 등도 검토할 예정이다[SEP] 이번에 검토할 예정인 것은 수소택시 부제 면제에 관한 것이다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]좋은점을 먼저 말하자면 기차역이랑 가까워요[SEP] 기차역과는 멀어요[SEP]', '0'],\n",
              " ['[CLS]위치가 중심가와 가까운 곳은 아니었습니다[SEP] 위치는 중심가 바로 옆이었습니다[SEP]', '0'],\n",
              " ['[CLS]강아지를 끔찍이도 좋아하는 12살 독일 소녀인 키라 클라우스 뮐러는 돈으로 인한 자기 부모의 다툼으로 인해 돈에 대한 안 좋은 감정을 갖게 된다[SEP] 키라 클라우스 뮐러는 돈에 대한 좋은 인상을 가지고 있다[SEP]',\n",
              "  '0'],\n",
              " ['[CLS]학교에서 강연할 때면 강조하는 것이 있습니다[SEP] 특히 대학생들에게 강조하는 것입니다[SEP]', '2'],\n",
              " ['[CLS]그 대신 해외 유입이 지역사회로 전파되는 것을 막기 위해 입국자들의 자가 격리에 주력하고 있다고 밝혔다[SEP] 해외 유입이 지역사회로 전파될 우려가 있다고 밝혔다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]시부야나 롯본기 등 이동하기에 좋습니다[SEP] 시부야로 이동하기에 좋습니다[SEP]', '1'],\n",
              " ['[CLS]물론 중심지의 편리함에 비교할수는 없겠죠[SEP] 중심지보다 교통이 불편합니다[SEP]', '2'],\n",
              " ['[CLS]10년전 나를 매료시켰던 묘하고 멋진영화[SEP] 10년 전에 나를 실망시켰던 영화[SEP]', '0'],\n",
              " ['[CLS]이 퍼포먼스는 6월 1일 대한민국 의병의 날을 맞아 신돌석장군 유적지에서 개최되는 제9회 의병의 날 기념식 사전홍보를 위해 특별히 준비했다[SEP] 이 퍼포먼스는 난타를 중심으로 이루어져 있다[SEP]',\n",
              "  '2'],\n",
              " ['[CLS]마치 좋은 친척집에 머문 느낌이었어요[SEP] 좋은 친척집처럼 느껴졌어요[SEP]', '1'],\n",
              " ['[CLS]한국교육과정평가원은 27일인 오늘 수능 채점결과를 발표하고 28일 성적표를 배부하겠다고 밝혔다[SEP] 한국교육과정평가원은 성적표를 배부할 날짜를 밝힌 적이 없다[SEP]',\n",
              "  '0'],\n",
              " ['[CLS]짐이 많으신 분들은 좀 힘들 수 있습니다[SEP] 짐이 많아도 전혀 힘들지 않습니다[SEP]', '0'],\n",
              " ['[CLS]이는 협동조합이 3일간 기록한 매출의 20배에 달하는 수치다[SEP] 협동조합의 매출은 많은 편이 아니다[SEP]', '2'],\n",
              " ['[CLS]1880년 에케르트는 일본의 해군으로부터 일본의 국가를 작곡해 달라는 부탁을 받았는데 그 당시 일본의 국가는 존재하지 않았다[SEP] 일본의 해군은 에케르트에게 국가를 부탁했다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]일찍이 인종이 왕세자로 있을 때 중종의 계비인 문정왕후가 명종을 낳자 중종은 이를 매우 사랑하였다[SEP] 문정왕후 이전에 다른 왕후가 있었다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]상당히 많은 것을 내포하고 있는 영화[SEP] 내포하고 있는 것이 상당히 많은 영화[SEP]', '1'],\n",
              " ['[CLS]뉴시스는 경찰이 10월 23일 오전 10시 고 백남기 농민의 부검 영장을 강제집행하기로 했다고 23일 보도했다[SEP] 뉴시스는 경찰이 백남기 농민의 부검 영장을 집행하지 않기로 했다고 23일 보도했다[SEP]',\n",
              "  '0'],\n",
              " ['[CLS]이와 함께 공단주변 하천 및 공장밀집지역 등에 대한 순찰 강화 등 환경감시활동을 하게 된다[SEP] 공단주변 하천은 오염으로 조사를 받은 적이 있다[SEP]',\n",
              "  '2'],\n",
              " ['[CLS]손목밴드를 분실한 경우에는 출입구에서 다시 받아야 해수욕장을 이용할 수 있다[SEP] 해수욕장을 이용하려면 손목밴드가 필요하다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]문래고가차도는 1979년 건설되었으며 영등포역과 신도림역을 잇는 경인로의 고가차도이다[SEP] 영등포역과 신도림역을 잇는 도로가 있다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]또한 내부 직원 송아무개씨가 차남과 공모해 인력 공급 업체를 차린 후 60억원을 가로챈 사실도 확인했다[SEP] 송모씨의 차남의 주도하에 인력 공급 업체를 차린 후 60억원을 가로챘다[SEP]',\n",
              "  '2'],\n",
              " ['[CLS]이곳은 물건을 단순히 사고 파는 공간이 아닌 독자와 직접 소통하고 다가갈 수 있는 공간이다[SEP] 이곳은 물건을 단순히 사고 파는 공간이 아니다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]인공지능이 탑재돼 대화를 나누고 게임을 할 수 있으며 인터넷에 접속하면 일기예보를 들려주거나 뉴스를 읽어준다[SEP] 탑재된 인공지능과 하는 대화의 수준은 업데이트를 통해 향상시킬 예정이다[SEP]',\n",
              "  '2'],\n",
              " ['[CLS]같은 해 6월 그는 파리에 콜레라가 유행하자 파리의 교외인 바르비종으로 옮기고 본격적인 농민 화가로서 전원생활의 정경을 그렸다[SEP] 6월에 파리에 콜레라가 유행했다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]이날 동문회에는 영남대 서길수 총장과 박재홍 대외협력부처장 등 대학 주요 관계자들도 함께했다[SEP] 대학 주요 관계자는 참석이 불가능했다[SEP]',\n",
              "  '0'],\n",
              " ['[CLS]김종식 목포시장이 지난 11월 30일 열린 제343회 목포시의회 제2차 정례회에서 2019년도 예산안을 제출하며 시정연설을 했다[SEP] 목포시의회의 정례회는 최초로 열렸다[SEP]',\n",
              "  '0'],\n",
              " ['[CLS]또 화재 진압을 위해 옥외 소화전 사용법을 익힐 예정이다[SEP] 옥외 소화전은 화재 진압을 위해 사용된다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]프로 바둑기사 아버지와 바둑학원 강사 출신 어머니 사이에서 태어났다[SEP] 아버지는 프로 바둑기사였다[SEP]', '1'],\n",
              " ['[CLS]해당 에디션의 가격은 8180 달러이며 이는 기존 제품 가격보다 약 4배 정도 더 비싼 것으로 알려졌다[SEP] 에디션 제품은 기존 제품보다 항상 더 비싸다[SEP]',\n",
              "  '2'],\n",
              " ['[CLS]해양수산부는 해양 녹조류 등으로 고부가가치의 친환경 해양바이오플라스틱 소재를 생산하는 기술 개발에 성공했다고 밝혔다[SEP] 친환경 해양바이오플라스틱 소재 생산에 해양 녹조류 등을 이용했다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]요즘에는 면과 함께 하이드로겔을 이용한 마스크팩 또는 천연소재를 이용한 바이오 셀룰로오스 마스크팩이 큰 인기를 끌고 있다[SEP] 천연소재를 이용한 바이오셀룰로오스 마스크팩의 가격은 오르고 있다[SEP]',\n",
              "  '2'],\n",
              " ['[CLS]이에 따라 경향신문이 해당 부분을 집필한 이명희 공주대 교수에게 문의를 해 본 결과 이는 쉽게 대답할 수 있는 것이 아니라며 대답을 회피하였다고 보도하였다[SEP] 이명희 공주대 교수는 경향신문의 문의에 대답을 회피하였다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]영화는 아이를 갖지 못하던 부부에게 어느 날 운석처럼 하늘에서 아이가 내려오며 이야기가 시작된다[SEP] 영화는 부부가 아이를 가지면서 이야기가 시작된다[SEP]',\n",
              "  '0'],\n",
              " ['[CLS]저렴하고 테라스가 있는 개인실 입니다[SEP] 가격이 싼 개인실입니다[SEP]', '1'],\n",
              " ['[CLS]유진은 딸 노을과 함께 한국으로 돌아와 뒤늦은 대학원 공부를 하는 중이다[SEP] 유진은 검정고시 공부를 하는 중이다[SEP]',\n",
              "  '0'],\n",
              " ['[CLS]이렇게 무리 없이 잠수함을 운영하는데에는 잠수함 사령부의 우수한 인력도 한 몫 한다[SEP] 우수한 인력도 잠수함을 무리 없이 운영하는데에 한 몫 한다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]최성순 씨의 아들 최현서 군은 학대받은 정황이 확인된 이후 충북의 한 장애인보호센터인 충주성심맹아원에서 생활하고 있다[SEP] 최현서 군은 학대받은 사실이 있다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]조엘이 기억을 지운 다음 날 아침 조엘과 클레멘타인은 우연히 다시 그들의 추억의 장소에서 서로를 만나게 된다[SEP] 조엘과 클레멘타인의 추억의 장소가 있다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]지난해 유독 여러 분야에 걸쳐 골고루 부족한 영화들이 많다고 평가받은 영향인지 다양한 망작 후보가 나왔다[SEP] 지난해 유독 부족한 영화들이 많다고 평가받았다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]17 미터 높이의 이순신 장군 동상은 1968년 만들어진 이래로 서울을 상징하는 대표적인 조형물로 시민들의 사랑을 받아왔다[SEP] 시민들은 서울시 조형물 중 이순신 장군 동상을 가장 좋아한다[SEP]',\n",
              "  '2'],\n",
              " ['[CLS]특히 발굴 36년 만에 처음으로 북분 금관과 금허리띠를 비롯한 여러 국보급의 귀중한 유물들이 관람객을 맞는다[SEP] 여러 국보급의 유물들이 관람객들에게 공개된다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]결혼한 지 얼마 되지 않은 부부 몰리와 자일즈는 친척에게서 물려받은 집으로 하숙집 몽크스웰 장을 새로 개업한다[SEP] 몰리와 자일즈는 신혼 부부이다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]군이 종합적으로 부실하게 사건을 수사한 것이 아니냐는 주장이 제기될 수 있는 지점입니다[SEP] 부실한 사건 수사는 사실 관계 파악을 어렵게 한다[SEP]',\n",
              "  '2'],\n",
              " ['[CLS]개인적으로 2편보단 1편이 좀 더 낫다고 생각한다[SEP] 2편이 1편보다 낫다[SEP]', '0'],\n",
              " ['[CLS]레그런드는 자신을 깨물었던 벌레를 잡았으나 남에게 빌려줘 버렸고 대신 지금은 벌레의 그림만 그렸놓았다고 한다[SEP] 벌레가 레그런드를 깨물었다[SEP]',\n",
              "  '1'],\n",
              " ['[CLS]많은 아일랜드 야사 사료들은 고대 아일랜드가 대체로 단일화된 사회로서 아르드리라는 세습군주의 지배하에 있었다고 기록한다[SEP] 많은 아일랜드 야사 사료에는 고대 아일랜드가 세습군주의 지배하에 있었다고 기록되어있다[SEP]',\n",
              "  '1']]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
      ],
      "metadata": {
        "id": "zbzrrPrIpkg2"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gluonnlp.data import SentencepieceTokenizer\n",
        "from kobert import get_tokenizer\n",
        "tok_path = get_tokenizer()\n",
        "sp  = SentencepieceTokenizer(tok_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDzzwWlXm3Xd",
        "outputId": "8fac01ef-c4ac-42e1-f3aa-dba299139f05"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "Gn0X8nNDIibo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac89bf79-0b3e-4e16-c9aa-aacab3630981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ],
      "source": [
        "# from kobert_transformers import get_tokenizer\n",
        "from kobert.utils import get_tokenizer\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "RCqgAJj8Iibp"
      },
      "outputs": [],
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "mpdIXJuVIibp"
      },
      "outputs": [],
      "source": [
        "## Setting parameters\n",
        "max_len = 256\n",
        "batch_size = 8\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 20\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "OScw27lPIibq"
      },
      "outputs": [],
      "source": [
        "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
        "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(data_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQkK6787LiYX",
        "outputId": "b7b9aa97-a93c-4fac-bccb-ab5ee1de992b"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([   2,  702,  638,  315,  517,  363,  807, 7119, 7926, 1259, 7234,\n",
              "        1106, 6079, 3803, 7784, 1767, 4012, 6003, 6412, 5859, 7095, 3394,\n",
              "        2856, 7095, 1713, 2095, 7344, 7078, 1442, 5330, 5400, 1771,  702,\n",
              "         687,  282,  333,  517,  363,  807, 7119, 7926, 1259, 7234, 1106,\n",
              "        3803, 5965, 6234, 6896, 2095, 7344, 7078, 1442, 5338,  702,  687,\n",
              "         282,  333,  517,  363,    3,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1], dtype=int32),\n",
              " array(60, dtype=int32),\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
              " 1)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "C70GxAF2Iibq"
      },
      "outputs": [],
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=4)\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['target'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rkbbyrglzwB",
        "outputId": "b17e000c-ba2a-45aa-ded7-58ab9fe4362f"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "snXpYUNKIibq"
      },
      "outputs": [],
      "source": [
        "# class BERTClassifier(nn.Module):\n",
        "#     def __init__(self,\n",
        "#                  bert,\n",
        "#                  hidden_size = 768,\n",
        "#                  num_classes=520,\n",
        "#                  dr_rate=None,\n",
        "#                  params=None):\n",
        "#         super(BERTClassifier, self).__init__()\n",
        "#         self.bert = bert\n",
        "#         self.dr_rate = dr_rate\n",
        "                 \n",
        "#         self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "#         if dr_rate:\n",
        "#             self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "#     def gen_attention_mask(self, token_ids, valid_length):\n",
        "#         attention_mask = torch.zeros_like(token_ids)\n",
        "#         for i, v in enumerate(valid_length):\n",
        "#             attention_mask[i][:v] = 1\n",
        "#         return attention_mask.float()\n",
        "\n",
        "#     def forward(self, token_ids, valid_length, segment_ids):\n",
        "#         attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "#         _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "#         if self.dr_rate:\n",
        "#             out = self.dropout(pooler)\n",
        "#         return self.classifier(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "zJpy7OS3Iibr"
      },
      "outputs": [],
      "source": [
        "# model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "l-WM_giBIibr"
      },
      "outputs": [],
      "source": [
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "3eCg9P36Iibr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "570a488a-570d-4788-a0bf-18a49af70f08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "pfRGFGzxIibr"
      },
      "outputs": [],
      "source": [
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "keKdf_mlIibs"
      },
      "outputs": [],
      "source": [
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "w5PKgBSCIibs"
      },
      "outputs": [],
      "source": [
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "SmH684nmIibs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432,
          "referenced_widgets": [
            "8cb645ef2fcc49aebe9511d9c6f1ae71",
            "afb6e768f66f493590fbb3e7476a44d1",
            "17e0a672d7f846b1bbb78393a9d42340",
            "f961812ec83d41bda2db10a4326d0d5e",
            "66cd0f5eeee8434696ebf63dabb9779d",
            "18e07f1d1a61449b8900d9c35d009eab",
            "7cac2fe5206d4448b979b9a825ac3362",
            "124b5a2968ef462ea890561ae5694b35",
            "bdd3b17e1c044d058d9cc6098bb8427f",
            "e04e1da028d347afbc808ae256350206",
            "c6848ec9801c43ca9d65eb2f2edeaba9"
          ]
        },
        "outputId": "38aa7613-73d7-4bec-823e-da22d686a561"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cb645ef2fcc49aebe9511d9c6f1ae71",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-64c337b7a74c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mvalid_length\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0;31m# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;31m# ourselves in which case we just need to make it broadcastable to all heads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_extended_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0;31m# If a 2D or 3D attention mask is provided for the cross-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mget_extended_attention_mask\u001b[0;34m(self, attention_mask, input_shape, device)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             raise ValueError(\n\u001b[0;32m--> 298\u001b[0;31m                 \u001b[0;34mf\"Wrong shape for input_ids (shape {input_shape}) or attention_mask (shape {attention_mask.shape})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m             )\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Wrong shape for input_ids (shape torch.Size([8, 256])) or attention_mask (shape torch.Size([8]))"
          ]
        }
      ],
      "source": [
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
        "    # torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_acc / (batch_id+1))"
      ],
      "metadata": {
        "id": "dYku3X4am8ES"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "KoBERT_IPC_Classification.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8cb645ef2fcc49aebe9511d9c6f1ae71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_afb6e768f66f493590fbb3e7476a44d1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_17e0a672d7f846b1bbb78393a9d42340",
              "IPY_MODEL_f961812ec83d41bda2db10a4326d0d5e",
              "IPY_MODEL_66cd0f5eeee8434696ebf63dabb9779d"
            ]
          }
        },
        "afb6e768f66f493590fbb3e7476a44d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17e0a672d7f846b1bbb78393a9d42340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_18e07f1d1a61449b8900d9c35d009eab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7cac2fe5206d4448b979b9a825ac3362"
          }
        },
        "f961812ec83d41bda2db10a4326d0d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_124b5a2968ef462ea890561ae5694b35",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2500,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bdd3b17e1c044d058d9cc6098bb8427f"
          }
        },
        "66cd0f5eeee8434696ebf63dabb9779d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e04e1da028d347afbc808ae256350206",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2500 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c6848ec9801c43ca9d65eb2f2edeaba9"
          }
        },
        "18e07f1d1a61449b8900d9c35d009eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7cac2fe5206d4448b979b9a825ac3362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "124b5a2968ef462ea890561ae5694b35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bdd3b17e1c044d058d9cc6098bb8427f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e04e1da028d347afbc808ae256350206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c6848ec9801c43ca9d65eb2f2edeaba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
